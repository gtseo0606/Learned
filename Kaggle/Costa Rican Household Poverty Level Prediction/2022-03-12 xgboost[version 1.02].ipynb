{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28336b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f56c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this only transforms the idhogar field, the other things this function used to do are done elsewhere\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "# plot feature importance for sklearn decision trees    \n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    if display_results:\n",
    "        # Print the feature ranking\n",
    "        print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[indices[f]])\n",
    "        \n",
    "        ranked_list.append(X_train.columns[indices[f]])\n",
    "        \n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(X_train.columns[indices[f]])\n",
    "            \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901dfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                 ('human_density', 'tamviv', 'rooms'),\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "                ]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "    \n",
    "    # aggregation rules over household\n",
    "    aggs_num = {'age': ['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    \n",
    "    aggs_cat = {'dis': ['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "\n",
    "    # aggregation over household\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "\n",
    "    # Drop id's\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ccf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot encoded fields to label encoding\n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi',\n",
    "               'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        #deal with those OHE, where there is a sum over columns == 0\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n",
    "                  .format(s_))\n",
    "            # dummy colmn name to be added\n",
    "            col_dummy = s_+'_dummy'\n",
    "            # add the column to the dataframe\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            # add the name to the list of columns to be label-encoded\n",
    "            cols_s_.append(col_dummy)\n",
    "            # proof-check, that now the category is complete\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                 print(\"The category completion did not work\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12df978",
   "metadata": {
    "_uuid": "eab84429fc9893c82e33b8319161c190b4104e9f"
   },
   "source": [
    "# Read in the data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59fa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283c37d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194104.    , 144612.    ,  17395.75  , ...,  85349.1875,\n",
       "        81779.1875,  81244.1875])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sum(axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5077cc8",
   "metadata": {
    "_uuid": "bd1f66cbdbfa4741d19a8b1f53793b967d62d281"
   },
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    # encode the idhogar\n",
    "    encode_data(df_)\n",
    "    \n",
    "    # create aggregate features\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3a0cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9552    5\n",
       "9553    5\n",
       "9554    5\n",
       "9555    5\n",
       "9556    5\n",
       "Name: tamhog, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tamhog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d51cb1",
   "metadata": {
    "_uuid": "aaf8a52a939c7d5bc548cbe4ecc1458caae60e7d"
   },
   "source": [
    "Clean up some missing data and convert objects to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890084fc",
   "metadata": {
    "_uuid": "65dab0e9a94e8f87a7b73e7ec2c6559e4ccef996",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some dependencies are Na, fill those with the square root of the square\n",
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "# fill \"no\"s for education with 0s\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "# if education is \"yes\" and person is head of household, fill with escolari\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# convert to int for our models\n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "train['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fill some nas\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0989b50d",
   "metadata": {
    "_uuid": "b564a6552f0521581af1ee38d6040ef7ae5d2fb5"
   },
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "\n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d677a50",
   "metadata": {
    "_uuid": "2695108e103c9c61088fc4c100d01bc8c0f4138c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "# convert the one hot fields into label encoded\n",
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b568ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9552    5\n",
       "9553    5\n",
       "9554    5\n",
       "9555    5\n",
       "9556    5\n",
       "Name: tamhog, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tamhog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbde0e5",
   "metadata": {
    "_uuid": "e90e68abd266c9db808dbf336308cef7175886bd"
   },
   "source": [
    "# Geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0866c9f4",
   "metadata": {
    "_uuid": "0ffc288b3829ffdb1dabf8f2e7fe518f2f520480"
   },
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], \n",
    "                                       columns=cols_2_ohe)],axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "# add some aggregates by geography\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7339068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9552    5\n",
       "9553    5\n",
       "9554    5\n",
       "9555    5\n",
       "9556    5\n",
       "Name: tamhog, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tamhog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f790d316",
   "metadata": {
    "_uuid": "bc96d527090d9b0723049c5d763c97be5145b8c7"
   },
   "outputs": [],
   "source": [
    "# add the number of people over 18 in each household\n",
    "train['num_over_18'] = 0\n",
    "#train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0)\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "#test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0)\n",
    "\n",
    "# add some extra features, these were taken from another kernel\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] # rooms per person\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] # rent to household size\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1736f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9552    5\n",
       "9553    5\n",
       "9554    5\n",
       "9555    5\n",
       "9556    5\n",
       "Name: tamhog, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tamhog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce7bb42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "23851    1\n",
       "23852    1\n",
       "23853    1\n",
       "23854    1\n",
       "23855    1\n",
       "Name: num_over_18, Length: 23856, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = 1\n",
    "test['num_over_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f1e7f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9557, 204)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1461ec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>...</th>\n",
       "      <th>num_over_18</th>\n",
       "      <th>bedrooms_to_rooms</th>\n",
       "      <th>rent_to_rooms</th>\n",
       "      <th>tamhog_to_rooms</th>\n",
       "      <th>r4t3_to_tamhog</th>\n",
       "      <th>r4t3_to_rooms</th>\n",
       "      <th>v2a1_to_r4t3</th>\n",
       "      <th>hhsize_to_rooms</th>\n",
       "      <th>rent_to_hhsize</th>\n",
       "      <th>rent_to_over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>63333.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>36000.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>36000.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7026 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  r4h1  r4h2  \\\n",
       "0     190000.0       0      3       0     1       1     0    0.0     0     1   \n",
       "1     135000.0       0      4       0     1       1     1    1.0     0     1   \n",
       "2          0.0       0      8       0     1       1     0    0.0     0     0   \n",
       "4     180000.0       0      5       0     1       1     1    1.0     0     2   \n",
       "5     180000.0       0      5       0     1       1     1    1.0     0     2   \n",
       "...        ...     ...    ...     ...   ...     ...   ...    ...   ...   ...   \n",
       "9551       0.0       0      3       0     1       1     0    0.0     0     1   \n",
       "9552   80000.0       0      6       0     1       1     0    0.0     0     2   \n",
       "9554   80000.0       0      6       0     1       1     0    0.0     0     2   \n",
       "9555   80000.0       0      6       0     1       1     0    0.0     0     2   \n",
       "9556   80000.0       0      6       0     1       1     0    0.0     0     2   \n",
       "\n",
       "      ...  num_over_18  bedrooms_to_rooms  rent_to_rooms  tamhog_to_rooms  \\\n",
       "0     ...            0           0.333333   63333.333333         0.333333   \n",
       "1     ...            0           0.250000   33750.000000         0.250000   \n",
       "2     ...            0           0.250000       0.000000         0.125000   \n",
       "4     ...            0           0.600000   36000.000000         0.800000   \n",
       "5     ...            0           0.600000   36000.000000         0.800000   \n",
       "...   ...          ...                ...            ...              ...   \n",
       "9551  ...            0           0.333333       0.000000         0.666667   \n",
       "9552  ...            0           0.666667   13333.333333         0.833333   \n",
       "9554  ...            0           0.666667   13333.333333         0.833333   \n",
       "9555  ...            0           0.666667   13333.333333         0.833333   \n",
       "9556  ...            0           0.666667   13333.333333         0.833333   \n",
       "\n",
       "      r4t3_to_tamhog  r4t3_to_rooms  v2a1_to_r4t3  hhsize_to_rooms  \\\n",
       "0                1.0       0.333333      190000.0         0.333333   \n",
       "1                1.0       0.250000      135000.0         0.250000   \n",
       "2                1.0       0.125000           0.0         0.125000   \n",
       "4                1.0       0.800000       60000.0         0.800000   \n",
       "5                1.0       0.800000       60000.0         0.800000   \n",
       "...              ...            ...           ...              ...   \n",
       "9551             1.0       0.666667           0.0         0.666667   \n",
       "9552             1.0       0.833333       20000.0         0.833333   \n",
       "9554             1.0       0.833333       20000.0         0.833333   \n",
       "9555             1.0       0.833333       20000.0         0.833333   \n",
       "9556             1.0       0.833333       20000.0         0.833333   \n",
       "\n",
       "      rent_to_hhsize  rent_to_over_18  \n",
       "0           190000.0         190000.0  \n",
       "1           135000.0         135000.0  \n",
       "2                0.0              0.0  \n",
       "4            45000.0         180000.0  \n",
       "5            45000.0         180000.0  \n",
       "...              ...              ...  \n",
       "9551             0.0              0.0  \n",
       "9552         16000.0          80000.0  \n",
       "9554         16000.0          80000.0  \n",
       "9555         16000.0          80000.0  \n",
       "9556         16000.0          80000.0  \n",
       "\n",
       "[7026 rows x 204 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.age >= 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a0980f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>...</th>\n",
       "      <th>num_over_18</th>\n",
       "      <th>bedrooms_to_rooms</th>\n",
       "      <th>rent_to_rooms</th>\n",
       "      <th>tamhog_to_rooms</th>\n",
       "      <th>r4t3_to_tamhog</th>\n",
       "      <th>r4t3_to_rooms</th>\n",
       "      <th>v2a1_to_r4t3</th>\n",
       "      <th>hhsize_to_rooms</th>\n",
       "      <th>rent_to_hhsize</th>\n",
       "      <th>rent_to_over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7026 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  r4h1  r4h2  ...  \\\n",
       "0        1       1      1       1     1       1     1      1     1     1  ...   \n",
       "1        1       1      1       1     1       1     1      1     1     1  ...   \n",
       "2        1       1      1       1     1       1     1      1     1     1  ...   \n",
       "4        2       2      2       2     2       2     2      2     2     2  ...   \n",
       "5        2       2      2       2     2       2     2      2     2     2  ...   \n",
       "...    ...     ...    ...     ...   ...     ...   ...    ...   ...   ...  ...   \n",
       "9551     2       2      2       2     2       2     2      2     2     2  ...   \n",
       "9552     4       4      4       4     4       4     4      4     4     4  ...   \n",
       "9554     4       4      4       4     4       4     4      4     4     4  ...   \n",
       "9555     4       4      4       4     4       4     4      4     4     4  ...   \n",
       "9556     4       4      4       4     4       4     4      4     4     4  ...   \n",
       "\n",
       "      num_over_18  bedrooms_to_rooms  rent_to_rooms  tamhog_to_rooms  \\\n",
       "0               1                  1              1                1   \n",
       "1               1                  1              1                1   \n",
       "2               1                  1              1                1   \n",
       "4               2                  2              2                2   \n",
       "5               2                  2              2                2   \n",
       "...           ...                ...            ...              ...   \n",
       "9551            2                  2              2                2   \n",
       "9552            4                  4              4                4   \n",
       "9554            4                  4              4                4   \n",
       "9555            4                  4              4                4   \n",
       "9556            4                  4              4                4   \n",
       "\n",
       "      r4t3_to_tamhog  r4t3_to_rooms  v2a1_to_r4t3  hhsize_to_rooms  \\\n",
       "0                  1              1             1                1   \n",
       "1                  1              1             1                1   \n",
       "2                  1              1             1                1   \n",
       "4                  2              2             2                2   \n",
       "5                  2              2             2                2   \n",
       "...              ...            ...           ...              ...   \n",
       "9551               2              2             2                2   \n",
       "9552               4              4             4                4   \n",
       "9554               4              4             4                4   \n",
       "9555               4              4             4                4   \n",
       "9556               4              4             4                4   \n",
       "\n",
       "      rent_to_hhsize  rent_to_over_18  \n",
       "0                  1                1  \n",
       "1                  1                1  \n",
       "2                  1                1  \n",
       "4                  2                2  \n",
       "5                  2                2  \n",
       "...              ...              ...  \n",
       "9551               2                2  \n",
       "9552               4                4  \n",
       "9554               4                4  \n",
       "9555               4                4  \n",
       "9556               4                4  \n",
       "\n",
       "[7026 rows x 203 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.age >= 18].groupby('idhogar').transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015bf1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d22f49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9552    0\n",
       "9553    0\n",
       "9554    0\n",
       "9555    0\n",
       "9556    0\n",
       "Name: num_over_18, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7570434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9552    0\n",
       "9553    0\n",
       "9554    0\n",
       "9555    0\n",
       "9556    0\n",
       "Name: num_over_18, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['num_over_18'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea235952",
   "metadata": {
    "_uuid": "a6ed97e10f021b42a19c7228dfc1a52ce9de2c60"
   },
   "outputs": [],
   "source": [
    "# drop duplicated columns\n",
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd110014",
   "metadata": {
    "_uuid": "c6e1ccce811e7a1d76282fcb8a13edf92672f834"
   },
   "source": [
    "## Split the data\n",
    "\n",
    "일반적으로 같은 가구에 속한 행이 동일한 대상을 가지므로 유출을 방지하기 위해 가구별로 데이터를 나누었습니다. 가장만 포함하도록 데이터를 필터링하기 때문에 기술적으로 필요하지 않지만, 전체 교육 데이터 세트를 사용하려면 쉽게 사용할 수 있습니다.\n",
    "\n",
    "데이터를 분할한 후에는 열차 데이터를 전체 데이터 세트로 덮어써서 모든 데이터에 대해 학습할 수 있습니다. split_data 함수는 데이터를 덮어쓰지 않고 동일한 작업을 수행하며 교육 루프 내에서 K-Fold split의 근사치를 구하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b30660e",
   "metadata": {
    "_uuid": "da37e677a32477006e8468b954e23d595c82eced"
   },
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    # uncomment for extra randomness\n",
    "#     np.random.seed(seed=seed)\n",
    "    \n",
    "    train2 = train.copy()\n",
    "    \n",
    "    # pick some random households to use for the test data\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    \n",
    "    # select households which are in the random selection\n",
    "    cv_idx = np.isin(households, cv_hhs) # [T,F,T,F,...]\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "298d8483",
   "metadata": {
    "_uuid": "e14a9619ca6516b225b55bf65d6a9e423d6b5fc7"
   },
   "outputs": [],
   "source": [
    "X = train.query('parentesco1==1')\n",
    "# X = train.copy()\n",
    "\n",
    "# pull out and drop the target variable\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "# train on entire dataset\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5565aefa",
   "metadata": {
    "_uuid": "871cd5b46da553f6062cef605acc761cddc2a8c0"
   },
   "outputs": [],
   "source": [
    "# 불균형한 class를 훈련하기 위한 class 가중치를 구하세요.\n",
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7825c644",
   "metadata": {
    "_uuid": "d9bcfbfcfc0b5b7e3aaeb2b0c8495bd92fdf51a3"
   },
   "outputs": [],
   "source": [
    "# LGBM에서 사용하지 않거나 중요도가 매우 낮은 일부 기능을 삭제합니다.\n",
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN',\n",
    " 'agg18_estadocivil6_COUNT',\n",
    " 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT',\n",
    " 'agg18_parentesco11_COUNT',\n",
    " 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT',\n",
    " 'agg18_parentesco2_COUNT',\n",
    " 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT',\n",
    " 'agg18_parentesco5_COUNT',\n",
    " 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT',\n",
    " 'agg18_parentesco8_COUNT',\n",
    " 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4',\n",
    " 'geo_energcocinar_LE_1',\n",
    " 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0',\n",
    " 'geo_hogar_mayor',\n",
    " 'geo_manual_elec_LE_2',\n",
    " 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4',\n",
    " 'geo_pared_LE_5',\n",
    " 'geo_pared_LE_6',\n",
    " 'num_over_18',\n",
    " 'parentesco_LE',\n",
    " 'rez_esc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17ecd9fb",
   "metadata": {
    "_uuid": "67a0f3b7d019517ed9a40b41df318284a33a5ce1"
   },
   "outputs": [],
   "source": [
    "xgb_drop_cols = extra_drop_features + [\"idhogar\",  'parentesco1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5628f1",
   "metadata": {
    "_uuid": "2dc384aeb44db2454978df78fdbb84b2b1ff3ced"
   },
   "source": [
    "# Fit a voting classifier\n",
    "Define a derived VotingClassifier class to be able to pass `fit_params` for early stopping. Vote based on LGBM models with early stopping based on macro F1 and decaying learning rate.\n",
    "\n",
    "The parameters are optimised with a random search in this kernel: https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9f97490",
   "metadata": {
    "_uuid": "629cf88dd0596a98d58487495e5b096636e2586a"
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "opt_parameters = {'max_depth':35, 'eta':0.1, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 1, 'num_class': 4, 'gamma': 2.0, 'colsample_bylevel': 0.9, 'subsample': 0.84, 'colsample_bytree': 0.88, 'reg_lambda': 0.40 }\n",
    "# 5\n",
    "opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# 6\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.75, 'colsample_bylevel': 0.95, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# # 7\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.12, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 3.25, 'colsample_bylevel': 0.95, 'subsample': 0.88, 'colsample_bytree': 0.88, 'reg_lambda': 0.35 }\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1) \n",
    "\n",
    "fit_params={\"early_stopping_rounds\":500,\n",
    "            \"eval_metric\" : evaluate_macroF1_lgb, \n",
    "            \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n",
    "            'verbose': False,\n",
    "           }\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d300ecc",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "101a2fd45bbbe6c7fb351513803550d4edeef2b3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "    \n",
    "    # randomly split the data so we have a test set for early stopping\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n",
    "        \n",
    "    # update the fit params with our new split\n",
    "    fit_params[\"eval_set\"] = [(X_test,y_test)]\n",
    "    \n",
    "    # fit the estimator\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, **fit_params)\n",
    "    \n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "        \n",
    "    # reject some estimators based on their performance on train and test sets\n",
    "    if threshold:\n",
    "        # if the valid score is very high we'll allow a little more leeway with the train scores\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "\n",
    "        # else recurse until we get a better one\n",
    "        else:\n",
    "            print(\"Unacceptable!!! Trying again...\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "    \n",
    "    else:\n",
    "        return estimator\n",
    "    \n",
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    '''\n",
    "    This implements the fit method of the VotingClassifier propagating fit_params\n",
    "    '''\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        \n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % self.voting)\n",
    "\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n",
    "                                 ' should be a list of (string, estimator)'\n",
    "                                 ' tuples')\n",
    "\n",
    "        if (self.weights is not None and\n",
    "                len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d estimators'\n",
    "                             % (len(self.weights), len(self.estimators)))\n",
    "\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is '\n",
    "                             'required to be a classifier!')\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n",
    "                                                 sample_weight=sample_weight, threshold=threshold, **fit_params)\n",
    "                for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a843892",
   "metadata": {
    "_uuid": "37b909c2aa273651b7bb57c69b939760f14f38f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29833\tvalidation_0-macroF1:0.63160\n",
      "[50]\tvalidation_0-mlogloss:0.90510\tvalidation_0-macroF1:0.57477\n",
      "[100]\tvalidation_0-mlogloss:0.89867\tvalidation_0-macroF1:0.57676\n",
      "[150]\tvalidation_0-mlogloss:0.89925\tvalidation_0-macroF1:0.56996\n",
      "[200]\tvalidation_0-mlogloss:0.89901\tvalidation_0-macroF1:0.57260\n",
      "[250]\tvalidation_0-mlogloss:0.90049\tvalidation_0-macroF1:0.56439\n",
      "[299]\tvalidation_0-mlogloss:0.90096\tvalidation_0-macroF1:0.56399\n",
      "Train F1: 0.8913828293502019\n",
      "Test F1: 0.44640128034184035\n",
      "[20:56:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30377\tvalidation_0-macroF1:0.62773\n",
      "[50]\tvalidation_0-mlogloss:0.92975\tvalidation_0-macroF1:0.62788\n",
      "[100]\tvalidation_0-mlogloss:0.92408\tvalidation_0-macroF1:0.62010\n",
      "[150]\tvalidation_0-mlogloss:0.92262\tvalidation_0-macroF1:0.61918\n",
      "[200]\tvalidation_0-mlogloss:0.91851\tvalidation_0-macroF1:0.62242\n",
      "[250]\tvalidation_0-mlogloss:0.91729\tvalidation_0-macroF1:0.61814\n",
      "[299]\tvalidation_0-mlogloss:0.91737\tvalidation_0-macroF1:0.61555\n",
      "Train F1: 0.8804813008814671\n",
      "Test F1: 0.41640814873948306\n",
      "[20:56:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30003\tvalidation_0-macroF1:0.60316\n",
      "[50]\tvalidation_0-mlogloss:0.94896\tvalidation_0-macroF1:0.58037\n",
      "[100]\tvalidation_0-mlogloss:0.94415\tvalidation_0-macroF1:0.57677\n",
      "[150]\tvalidation_0-mlogloss:0.94213\tvalidation_0-macroF1:0.58269\n",
      "[200]\tvalidation_0-mlogloss:0.94340\tvalidation_0-macroF1:0.58184\n",
      "[250]\tvalidation_0-mlogloss:0.94431\tvalidation_0-macroF1:0.58846\n",
      "[299]\tvalidation_0-mlogloss:0.94312\tvalidation_0-macroF1:0.58555\n",
      "Train F1: 0.9084322529520236\n",
      "Test F1: 0.42611317254174397\n",
      "[20:57:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:57:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30425\tvalidation_0-macroF1:0.62190\n",
      "[50]\tvalidation_0-mlogloss:0.92850\tvalidation_0-macroF1:0.56233\n",
      "[100]\tvalidation_0-mlogloss:0.92775\tvalidation_0-macroF1:0.55402\n",
      "[150]\tvalidation_0-mlogloss:0.93337\tvalidation_0-macroF1:0.55866\n",
      "[200]\tvalidation_0-mlogloss:0.93382\tvalidation_0-macroF1:0.55219\n",
      "[250]\tvalidation_0-mlogloss:0.93329\tvalidation_0-macroF1:0.55711\n",
      "[299]\tvalidation_0-mlogloss:0.93419\tvalidation_0-macroF1:0.56174\n",
      "Train F1: 0.8954387576358561\n",
      "Test F1: 0.45686381841400875\n",
      "[20:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30108\tvalidation_0-macroF1:0.63195\n",
      "[50]\tvalidation_0-mlogloss:0.94076\tvalidation_0-macroF1:0.57974\n",
      "[100]\tvalidation_0-mlogloss:0.93571\tvalidation_0-macroF1:0.58651\n",
      "[150]\tvalidation_0-mlogloss:0.93378\tvalidation_0-macroF1:0.58900\n",
      "[200]\tvalidation_0-mlogloss:0.93319\tvalidation_0-macroF1:0.58304\n",
      "[250]\tvalidation_0-mlogloss:0.93267\tvalidation_0-macroF1:0.58373\n",
      "[299]\tvalidation_0-mlogloss:0.93111\tvalidation_0-macroF1:0.59262\n",
      "Train F1: 0.9229836466311064\n",
      "Test F1: 0.42770128148011266\n",
      "[20:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30172\tvalidation_0-macroF1:0.61078\n",
      "[50]\tvalidation_0-mlogloss:0.90663\tvalidation_0-macroF1:0.59538\n",
      "[100]\tvalidation_0-mlogloss:0.89851\tvalidation_0-macroF1:0.58462\n",
      "[150]\tvalidation_0-mlogloss:0.89703\tvalidation_0-macroF1:0.59180\n",
      "[200]\tvalidation_0-mlogloss:0.89860\tvalidation_0-macroF1:0.60852\n",
      "[250]\tvalidation_0-mlogloss:0.89899\tvalidation_0-macroF1:0.60465\n",
      "[299]\tvalidation_0-mlogloss:0.89913\tvalidation_0-macroF1:0.61324\n",
      "Train F1: 0.9132374131263072\n",
      "Test F1: 0.41653797325640435\n",
      "[20:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30351\tvalidation_0-macroF1:0.64047\n",
      "[50]\tvalidation_0-mlogloss:0.91310\tvalidation_0-macroF1:0.59431\n",
      "[100]\tvalidation_0-mlogloss:0.90861\tvalidation_0-macroF1:0.59204\n",
      "[150]\tvalidation_0-mlogloss:0.91004\tvalidation_0-macroF1:0.59451\n",
      "[200]\tvalidation_0-mlogloss:0.90826\tvalidation_0-macroF1:0.59662\n",
      "[250]\tvalidation_0-mlogloss:0.90381\tvalidation_0-macroF1:0.60015\n",
      "[299]\tvalidation_0-mlogloss:0.90611\tvalidation_0-macroF1:0.59802\n",
      "Train F1: 0.9010984566861765\n",
      "Test F1: 0.4121921013690677\n",
      "[20:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30455\tvalidation_0-macroF1:0.66302\n",
      "[50]\tvalidation_0-mlogloss:0.92302\tvalidation_0-macroF1:0.60598\n",
      "[100]\tvalidation_0-mlogloss:0.91818\tvalidation_0-macroF1:0.60993\n",
      "[150]\tvalidation_0-mlogloss:0.91575\tvalidation_0-macroF1:0.60350\n",
      "[200]\tvalidation_0-mlogloss:0.91573\tvalidation_0-macroF1:0.60376\n",
      "[250]\tvalidation_0-mlogloss:0.91575\tvalidation_0-macroF1:0.60609\n",
      "[299]\tvalidation_0-mlogloss:0.91497\tvalidation_0-macroF1:0.60483\n",
      "Train F1: 0.8995046720808137\n",
      "Test F1: 0.40966218051904824\n",
      "[20:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29689\tvalidation_0-macroF1:0.62265\n",
      "[50]\tvalidation_0-mlogloss:0.88630\tvalidation_0-macroF1:0.56040\n",
      "[100]\tvalidation_0-mlogloss:0.88243\tvalidation_0-macroF1:0.56810\n",
      "[150]\tvalidation_0-mlogloss:0.88046\tvalidation_0-macroF1:0.56490\n",
      "[200]\tvalidation_0-mlogloss:0.88247\tvalidation_0-macroF1:0.55782\n",
      "[250]\tvalidation_0-mlogloss:0.88294\tvalidation_0-macroF1:0.56354\n",
      "[299]\tvalidation_0-mlogloss:0.88368\tvalidation_0-macroF1:0.56163\n",
      "Train F1: 0.8941926613068671\n",
      "Test F1: 0.44784056257610827\n",
      "[20:59:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:59:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.31002\tvalidation_0-macroF1:0.67996\n",
      "[50]\tvalidation_0-mlogloss:0.90463\tvalidation_0-macroF1:0.58994\n",
      "[100]\tvalidation_0-mlogloss:0.89939\tvalidation_0-macroF1:0.59991\n",
      "[150]\tvalidation_0-mlogloss:0.89683\tvalidation_0-macroF1:0.59635\n",
      "[200]\tvalidation_0-mlogloss:0.89693\tvalidation_0-macroF1:0.59823\n",
      "[250]\tvalidation_0-mlogloss:0.89519\tvalidation_0-macroF1:0.60464\n",
      "[299]\tvalidation_0-mlogloss:0.89404\tvalidation_0-macroF1:0.60372\n",
      "Train F1: 0.8954358307144916\n",
      "Test F1: 0.4116266515630798\n",
      "[21:00:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:00:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29873\tvalidation_0-macroF1:0.64866\n",
      "[50]\tvalidation_0-mlogloss:0.92730\tvalidation_0-macroF1:0.56484\n",
      "[100]\tvalidation_0-mlogloss:0.92172\tvalidation_0-macroF1:0.58348\n",
      "[150]\tvalidation_0-mlogloss:0.92212\tvalidation_0-macroF1:0.58332\n",
      "[200]\tvalidation_0-mlogloss:0.92486\tvalidation_0-macroF1:0.57675\n",
      "[250]\tvalidation_0-mlogloss:0.92535\tvalidation_0-macroF1:0.57710\n",
      "[299]\tvalidation_0-mlogloss:0.92644\tvalidation_0-macroF1:0.57809\n",
      "Train F1: 0.8916511571154764\n",
      "Test F1: 0.44952686380858\n",
      "[21:00:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:00:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29853\tvalidation_0-macroF1:0.63248\n",
      "[50]\tvalidation_0-mlogloss:0.92265\tvalidation_0-macroF1:0.58589\n",
      "[100]\tvalidation_0-mlogloss:0.91719\tvalidation_0-macroF1:0.58276\n",
      "[150]\tvalidation_0-mlogloss:0.91876\tvalidation_0-macroF1:0.58146\n",
      "[200]\tvalidation_0-mlogloss:0.92002\tvalidation_0-macroF1:0.58413\n",
      "[250]\tvalidation_0-mlogloss:0.92027\tvalidation_0-macroF1:0.58530\n",
      "[299]\tvalidation_0-mlogloss:0.92062\tvalidation_0-macroF1:0.58394\n",
      "Train F1: 0.906915335997043\n",
      "Test F1: 0.4211063991164743\n",
      "[21:00:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:00:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29836\tvalidation_0-macroF1:0.59884\n",
      "[50]\tvalidation_0-mlogloss:0.91298\tvalidation_0-macroF1:0.58002\n",
      "[100]\tvalidation_0-mlogloss:0.90699\tvalidation_0-macroF1:0.58429\n",
      "[150]\tvalidation_0-mlogloss:0.90318\tvalidation_0-macroF1:0.58469\n",
      "[200]\tvalidation_0-mlogloss:0.90192\tvalidation_0-macroF1:0.59095\n",
      "[250]\tvalidation_0-mlogloss:0.90217\tvalidation_0-macroF1:0.59210\n",
      "[299]\tvalidation_0-mlogloss:0.90114\tvalidation_0-macroF1:0.59397\n",
      "Train F1: 0.8368028120280715\n",
      "Test F1: 0.435755837872174\n",
      "[21:01:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:01:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30963\tvalidation_0-macroF1:0.63537\n",
      "[50]\tvalidation_0-mlogloss:0.93058\tvalidation_0-macroF1:0.59600\n",
      "[100]\tvalidation_0-mlogloss:0.92499\tvalidation_0-macroF1:0.58409\n",
      "[150]\tvalidation_0-mlogloss:0.92423\tvalidation_0-macroF1:0.57915\n",
      "[200]\tvalidation_0-mlogloss:0.91901\tvalidation_0-macroF1:0.57842\n",
      "[250]\tvalidation_0-mlogloss:0.91853\tvalidation_0-macroF1:0.58174\n",
      "[299]\tvalidation_0-mlogloss:0.91710\tvalidation_0-macroF1:0.57982\n",
      "Train F1: 0.9291367483811608\n",
      "Test F1: 0.4220108303697399\n",
      "[21:01:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:01:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29451\tvalidation_0-macroF1:0.62019\n",
      "[50]\tvalidation_0-mlogloss:0.88408\tvalidation_0-macroF1:0.57025\n",
      "[100]\tvalidation_0-mlogloss:0.88040\tvalidation_0-macroF1:0.56180\n",
      "[150]\tvalidation_0-mlogloss:0.87765\tvalidation_0-macroF1:0.56187\n",
      "[200]\tvalidation_0-mlogloss:0.87653\tvalidation_0-macroF1:0.55871\n",
      "[250]\tvalidation_0-mlogloss:0.87689\tvalidation_0-macroF1:0.56591\n",
      "[299]\tvalidation_0-mlogloss:0.87780\tvalidation_0-macroF1:0.56591\n",
      "Train F1: 0.9266231110269063\n",
      "Test F1: 0.44309721269564134\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "    \n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "    \n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del(clfs)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50befbb5",
   "metadata": {
    "_uuid": "241d2973497b8eb2e5214f5c8ddb76432576ba35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.7587\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8936\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "# params 4 - 400 early stop - 15 estimators - l1 used features - weighted\n",
    "global_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ae346b4",
   "metadata": {
    "_uuid": "527b58d849cc1282909f15596cd5441ef4cac93d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil4_COUNT',\n",
       " 'agg18_estadocivil5_COUNT',\n",
       " 'geo_energcocinar_LE_0',\n",
       " 'geo_epared_LE_2',\n",
       " 'geo_pared_LE_0'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see which features are not used by ANY models\n",
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a86f2c4",
   "metadata": {
    "_uuid": "71dae26394955fcf940feea1c9ba1a5bcf134ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 42 (0.020635) - fe_children_fraction\n",
      "2. feature 59 (0.018743) - agg18_escolari_MAX\n",
      "3. feature 74 (0.017436) - agg18_parentesco2_MEAN\n",
      "4. feature 40 (0.015927) - SQBdependency\n",
      "5. feature 133 (0.015144) - geo_pared_LE_1\n",
      "6. feature 60 (0.014909) - agg18_escolari_MEAN\n",
      "7. feature 34 (0.013318) - SQBescolari\n",
      "8. feature 22 (0.013295) - dependency\n",
      "9. feature 114 (0.013293) - geo_epared_LE_1\n",
      "10. feature 37 (0.012348) - SQBedjefe\n",
      "11. feature 112 (0.011681) - geo_etecho_LE_1\n",
      "12. feature 100 (0.010705) - geo_age\n",
      "13. feature 39 (0.010649) - SQBovercrowding\n",
      "14. feature 109 (0.010639) - geo_eviv_LE_1\n",
      "15. feature 87 (0.010421) - piso_LE\n",
      "16. feature 11 (0.010405) - r4m3\n",
      "17. feature 117 (0.010371) - geo_elimbasu_LE_1\n",
      "18. feature 12 (0.010326) - r4t1\n",
      "19. feature 96 (0.010225) - estadocivil_LE\n",
      "20. feature 41 (0.010093) - SQBmeaned\n",
      "21. feature 15 (0.010045) - cielorazo\n",
      "22. feature 94 (0.010000) - etecho_LE\n",
      "23. feature 49 (0.009888) - fe_mobile_density\n",
      "24. feature 105 (0.009668) - geo_hogar_total\n",
      "25. feature 93 (0.009659) - epared_LE\n",
      "26. feature 95 (0.009378) - eviv_LE\n",
      "27. feature 98 (0.009354) - tipovivi_LE\n",
      "28. feature 14 (0.009294) - escolari\n",
      "29. feature 107 (0.009236) - geo_overcrowding\n",
      "30. feature 137 (0.009146) - rent_to_rooms\n",
      "31. feature 23 (0.009133) - edjefe\n",
      "32. feature 5 (0.009027) - v18q1\n",
      "33. feature 58 (0.008946) - agg18_escolari_MIN\n",
      "34. feature 13 (0.008912) - r4t2\n",
      "35. feature 92 (0.008907) - elimbasu_LE\n",
      "36. feature 17 (0.008888) - male\n",
      "37. feature 65 (0.008863) - agg18_estadocivil3_MEAN\n",
      "38. feature 104 (0.008838) - geo_hogar_adul\n",
      "39. feature 19 (0.008793) - hogar_adul\n",
      "40. feature 63 (0.008783) - agg18_estadocivil2_MEAN\n",
      "41. feature 25 (0.008716) - meaneduc\n",
      "42. feature 116 (0.008609) - geo_elimbasu_LE_0\n",
      "43. feature 55 (0.008594) - agg18_age_MIN\n",
      "44. feature 27 (0.008565) - overcrowding\n",
      "45. feature 46 (0.008565) - fe_human_bed_density\n",
      "46. feature 3 (0.008410) - hacapo\n",
      "47. feature 120 (0.008388) - geo_elimbasu_LE_5\n",
      "48. feature 51 (0.008306) - fe_mobile_adult_density\n",
      "49. feature 128 (0.008298) - geo_manual_elec_LE_0\n",
      "50. feature 69 (0.008243) - agg18_estadocivil5_MEAN\n",
      "51. feature 33 (0.008176) - age\n",
      "52. feature 124 (0.008172) - geo_sanitario_LE_1\n",
      "53. feature 10 (0.008167) - r4m2\n",
      "54. feature 106 (0.008162) - geo_bedrooms\n",
      "55. feature 35 (0.008141) - SQBage\n",
      "56. feature 97 (0.008112) - lugar_LE\n",
      "57. feature 102 (0.008105) - geo_dependency\n",
      "58. feature 45 (0.008035) - fe_human_density\n",
      "59. feature 86 (0.008022) - pared_LE\n",
      "60. feature 44 (0.007976) - fe_all_man_fraction\n",
      "61. feature 1 (0.007971) - hacdor\n",
      "62. feature 61 (0.007894) - agg18_dis_MEAN\n",
      "63. feature 7 (0.007749) - r4h2\n",
      "64. feature 43 (0.007731) - fe_working_man_fraction\n",
      "65. feature 26 (0.007684) - bedrooms\n",
      "66. feature 122 (0.007662) - geo_energcocinar_LE_3\n",
      "67. feature 119 (0.007599) - geo_elimbasu_LE_3\n",
      "68. feature 72 (0.007598) - agg18_estadocivil7_MEAN\n",
      "69. feature 56 (0.007573) - agg18_age_MAX\n",
      "70. feature 71 (0.007509) - agg18_estadocivil6_MEAN\n",
      "71. feature 31 (0.007472) - area1\n",
      "72. feature 57 (0.007316) - agg18_age_MEAN\n",
      "73. feature 0 (0.007278) - v2a1\n",
      "74. feature 18 (0.007260) - hogar_nin\n",
      "75. feature 4 (0.007216) - refrig\n",
      "76. feature 91 (0.007182) - energcocinar_LE\n",
      "77. feature 47 (0.007181) - fe_rent_per_person\n",
      "78. feature 30 (0.007136) - qmobilephone\n",
      "79. feature 2 (0.007094) - rooms\n",
      "80. feature 90 (0.007089) - sanitario_LE\n",
      "81. feature 136 (0.007083) - bedrooms_to_rooms\n",
      "82. feature 62 (0.006995) - agg18_estadocivil1_COUNT\n",
      "83. feature 111 (0.006987) - geo_etecho_LE_0\n",
      "84. feature 24 (0.006977) - edjefa\n",
      "85. feature 21 (0.006964) - hogar_total\n",
      "86. feature 144 (0.006920) - rent_to_over_18\n",
      "87. feature 36 (0.006896) - SQBhogar_total\n",
      "88. feature 138 (0.006818) - tamhog_to_rooms\n",
      "89. feature 52 (0.006748) - fe_tablet_adult_density\n",
      "90. feature 140 (0.006693) - r4t3_to_rooms\n",
      "91. feature 143 (0.006597) - rent_to_hhsize\n",
      "92. feature 29 (0.006535) - television\n",
      "93. feature 16 (0.006503) - dis\n",
      "94. feature 8 (0.006334) - r4h3\n",
      "95. feature 20 (0.006315) - hogar_mayor\n",
      "96. feature 6 (0.006190) - r4h1\n",
      "97. feature 125 (0.006190) - geo_sanitario_LE_2\n",
      "98. feature 67 (0.006074) - agg18_estadocivil4_MEAN\n",
      "99. feature 48 (0.005976) - fe_rent_per_room\n",
      "100. feature 50 (0.005848) - fe_tablet_density\n",
      "101. feature 75 (0.005761) - agg18_parentesco3_MEAN\n",
      "102. feature 101 (0.005431) - geo_meaneduc\n",
      "103. feature 99 (0.005383) - manual_elec_LE\n",
      "104. feature 81 (0.005245) - agg18_parentesco9_MEAN\n",
      "105. feature 79 (0.005242) - agg18_parentesco7_MEAN\n",
      "106. feature 126 (0.005194) - geo_sanitario_LE_3\n",
      "107. feature 141 (0.005184) - v2a1_to_r4t3\n",
      "108. feature 83 (0.005183) - agg18_parentesco11_MEAN\n",
      "109. feature 89 (0.005131) - abastagua_LE\n",
      "110. feature 129 (0.005076) - geo_manual_elec_LE_1\n",
      "111. feature 85 (0.004906) - edjef\n",
      "112. feature 53 (0.004902) - fe_people_not_living\n",
      "113. feature 32 (0.004852) - area2\n",
      "114. feature 28 (0.004779) - computer\n",
      "115. feature 88 (0.004725) - techo_LE\n",
      "116. feature 78 (0.004597) - agg18_parentesco6_MEAN\n",
      "117. feature 9 (0.004233) - r4m1\n",
      "118. feature 64 (0.004210) - agg18_estadocivil2_COUNT\n",
      "119. feature 38 (0.004113) - SQBhogar_nin\n",
      "120. feature 77 (0.003303) - agg18_parentesco5_MEAN\n",
      "121. feature 142 (0.002729) - hhsize_to_rooms\n",
      "122. feature 84 (0.002625) - agg18_parentesco12_MEAN\n",
      "123. feature 76 (0.002357) - agg18_parentesco4_MEAN\n",
      "124. feature 80 (0.001466) - agg18_parentesco8_MEAN\n",
      "125. feature 139 (0.001454) - r4t3_to_tamhog\n",
      "126. feature 127 (0.000000) - geo_sanitario_LE_4\n",
      "127. feature 70 (0.000000) - agg18_estadocivil5_COUNT\n",
      "128. feature 103 (0.000000) - geo_hogar_nin\n",
      "129. feature 73 (0.000000) - agg18_parentesco1_MEAN\n",
      "130. feature 108 (0.000000) - geo_eviv_LE_0\n",
      "131. feature 68 (0.000000) - agg18_estadocivil4_COUNT\n",
      "132. feature 82 (0.000000) - agg18_parentesco10_MEAN\n",
      "133. feature 110 (0.000000) - geo_eviv_LE_2\n",
      "134. feature 54 (0.000000) - fe_people_weird_stat\n",
      "135. feature 113 (0.000000) - geo_etecho_LE_2\n",
      "136. feature 121 (0.000000) - geo_energcocinar_LE_0\n",
      "137. feature 115 (0.000000) - geo_epared_LE_2\n",
      "138. feature 135 (0.000000) - geo_pared_LE_7\n",
      "139. feature 134 (0.000000) - geo_pared_LE_2\n",
      "140. feature 132 (0.000000) - geo_pared_LE_0\n",
      "141. feature 131 (0.000000) - geo_manual_elec_LE_4\n",
      "142. feature 118 (0.000000) - geo_elimbasu_LE_2\n",
      "143. feature 130 (0.000000) - geo_manual_elec_LE_3\n",
      "144. feature 66 (0.000000) - agg18_estadocivil3_COUNT\n",
      "145. feature 123 (0.000000) - geo_sanitario_LE_0\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27259a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959671f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a76ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb25d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae1978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b9009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fb2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09965f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48871130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2060c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bfc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ee2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80500541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1de7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf49ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc69edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fd7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
