{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58ef1a47-96bc-416d-a016-938a494fb1c3",
    "_uuid": "b531642dd4c3a53e20e5f6b9076bf17e9418e1e4"
   },
   "source": [
    "# WavCeption V1: just a 1-D Inception approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e68a3daa-14d7-46d7-a0db-9f80380b9d0f",
    "_uuid": "f597ce3d9e1e9fe818cf0a8e51f6da2404ba5b43"
   },
   "source": [
    "저는 단지 제가 가지고 놀던 작은 장난감을 공유하고 싶었을 뿐인데 **놀라운 결과**를 주었습니다. 지금은 시간이 없기 때문에, 사람들이 어떻게 가지고 놀지 보려고 공유하려고 합니다. :-D. **WavCception V1** 네트워크는 일반 컨볼루션 뉴럴 네트워크에 비해 인상적인 결과를 얻을 수 있는 것으로 보이지만, 이번 경쟁에서는 전처리 및 알려지지 않은 트랙 관리에 많은 노력이 필요한 것으로 보입니다. 이것은 구글의 초기 네트워크를 기반으로 합니다. 같은 아이디어입니다. \n",
    "\n",
    " 저는 몇 주 전에 이러한 모듈들을 캐스케이드로 연결하여 쉽게 1D 인셉션 네트워크를 구축할 수 있도록 구현하는 모듈을 작성했습니다(아래 참조).\n",
    " \n",
    " 아쉽게도 몇 가지 Kaggle의 제약으로 인해 커널 머신에서는 실행되지 않으므로 다운로드하여 자신의 머신에서 실행해 보시기 바랍니다.\n",
    " \n",
    " 너무 고생하지 않고 12시간 동안 모델을 실행함으로써 리더보드에서 0.76을 달성했습니다(로컬 테스트에서는 0.84). 같은 라인의 다른 시험에서는 로컬에서 0.89를 얻었기 때문에 알려지지 않은 클립을 처리하는 방법이 크게 개선되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd3e1543-18e2-4be6-b511-5c1e734d2c60",
    "_uuid": "f924854d4d258cd9a7db10eb5566e0bdff085574"
   },
   "source": [
    "## Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "cb0f537e-1932-4c45-a4d0-59e7d2caac6b",
    "_uuid": "9d73d1472e8ea2c21b0c70b5f537a74a9c562708"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil # shutil 모듈은 파일과 파일 모음에 대한 여러 가지 고수준 연산을 제공합니다. 특히, 파일 복사와 삭제를 지원하는 함수가 제공됩니다\n",
    "import glob # 파일 리스트 추출\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm # 진행표시바\n",
    "from collections import Counter # Counter('hello world') # Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython # 인터렉티브 파이썬\n",
    "from numpy.fft import rfft, irfft # 1차원 이산 푸리에변환 # 역푸리에변환\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8220812-116f-4f9b-a855-4b836f7411fc",
    "_uuid": "89ca39590c40bc3e332bab39fcedc7f2670b0f99"
   },
   "source": [
    "## Noise generation functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "890ea515-323c-46ae-884f-9cc71cf19d08",
    "_uuid": "d2d4594b05edbaf2eb450959812b741b8cfed6dc"
   },
   "source": [
    "이 섹션의 코드는 다음 항목에서 차용 및 개조되었습니다.\n",
    "https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "a401d022-6475-4155-8282-94acd8c81fd7",
    "_uuid": "df4bdf2dc7234238c43e495a393ea824ae5e6e82"
   },
   "outputs": [],
   "source": [
    "def ms(x): # 제곱평균\n",
    "    \"\"\"Mean value of signal `x` squared.\n",
    "    :param x: Dynamic quantity.\n",
    "    :returns: Mean squared of `x`.\n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "def normalize(y, x=None): # 일부(y)/전체(루트(제곱평균))\n",
    "    \"\"\"normalize power in y to a (standard normal) white noise signal.\n",
    "    Optionally normalize to power in signal `x`.\n",
    "    #The mean power of a Gaussian with :math:`\\\\mu=0` and :math:`\\\\sigma=1` is 1.\n",
    "    \"\"\"\n",
    "    #return y * np.sqrt( (np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean() )\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) ) # y/루트(제곱평균y)\n",
    "    #return y * np.sqrt( ms(x) / (np.abs(y)**2.0).mean() )\n",
    "    #return y * np.sqrt( 1.0 / (np.abs(y)**2.0).mean() )\n",
    "\n",
    "def white_noise(N, state=None): # N=16000*30, state=np.random.RandomState(655321)\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N) # 정규분포\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Blue noise. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with 6 dB per octave.\n",
    "    Power density increases with 3 dB per octave. \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise.\n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power decreases with -3 dB per octave.\n",
    "    Power density decreases with 6 dB per octave. \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise. Power increases with 6 dB per octave. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with +9 dB per octave.\n",
    "    Power density increases with +6 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\n\\nN = 10\\nstate = np.random.RandomState()\\nstate.randn(N)\\n\\n# array([-0.59026399, -0.68431962,  1.56870611, -1.10500642, -0.67393401,\\n#        0.10376222, -0.31171382, -0.35720405, -0.74424293,  0.12614498])\\n\\nN//2+1+uneven # 6\\nX = state.randn(N//2+1+uneven) # array([-0.17811637,  0.56738609,  0.1139559 , -0.1609064 , -0.0583465 , 0.09898859])\\nstate = np.random.RandomState()\\nuneven = N%2 # 나머지\\nX = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven) \\n#array([-0.67854019+0.33696715j, -0.53639523-1.33228336j,\\n#       -0.16807449-1.02284005j,  0.57717245+0.56470304j,\\n#       -0.563283  +1.19573055j, -1.07630368+0.5818659j ])\\nS = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero \\n# array([1.        , 1.41421356, 1.73205081, 2.        , 2.23606798,       2.44948974])\\n\\nX = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\\nS = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\\ny = (irfft(X/S)).real\\n\\nif uneven:\\n    y = y[:-1]\\nnormalize(y)\\n\\n#array([-1.13220548,  0.52472321,  1.24908875,  0.27902739, -0.36896684,\\n#       -0.32109447, -1.36113839, -1.96029794, -0.84810501, -0.38821552])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "state = np.random.RandomState()\n",
    "state.randn(N)\n",
    "\n",
    "# array([-0.59026399, -0.68431962,  1.56870611, -1.10500642, -0.67393401,\n",
    "#        0.10376222, -0.31171382, -0.35720405, -0.74424293,  0.12614498])\n",
    "\n",
    "N//2+1+uneven # 6\n",
    "X = state.randn(N//2+1+uneven) # array([-0.17811637,  0.56738609,  0.1139559 , -0.1609064 , -0.0583465 , 0.09898859])\n",
    "state = np.random.RandomState()\n",
    "uneven = N%2 # 나머지\n",
    "\n",
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven) \n",
    "#array([-0.67854019+0.33696715j, -0.53639523-1.33228336j,\n",
    "#       -0.16807449-1.02284005j,  0.57717245+0.56470304j,\n",
    "#       -0.563283  +1.19573055j, -1.07630368+0.5818659j ])\n",
    "\n",
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero \n",
    "# array([1.        , 1.41421356, 1.73205081, 2.        , 2.23606798,       2.44948974])\n",
    "\n",
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "y = (irfft(X/S)).real\n",
    "\n",
    "if uneven:\n",
    "    y = y[:-1]\n",
    "normalize(y)\n",
    "\n",
    "#array([-1.13220548,  0.52472321,  1.24908875,  0.27902739, -0.36896684,\n",
    "#       -0.32109447, -1.36113839, -1.96029794, -0.84810501, -0.38821552])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f08a3dd0-fb34-4415-a24d-795c2a475b3f",
    "_uuid": "a0c5d5315f8f420ba504c26f4ef0ed6d97a4aa57"
   },
   "source": [
    "## Tensorflow utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f7c51859-aedb-4da5-87e2-8ecf0d41425e",
    "_uuid": "ea75d0aee8fe1d444af7201364c62bc358ba38ab"
   },
   "source": [
    "텐서플로우 공통 작업을 모듈화하기 위한 유틸리티입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "93fe476d-5f7b-40b1-a074-1a0e9d50ce11",
    "_uuid": "7a782f5e128b8c429c9df8489276c8147ed365f2"
   },
   "outputs": [],
   "source": [
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1): # memory_fraction=1 : 100% 사용 # configuration : 구성\n",
    "    \"\"\"\n",
    "    사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 기능입니다.\n",
    "    1. device: 사용할 장치를 지정합니다(str)\n",
    "    2. memory_fraction: 할당해야 하는 메모리의 비율입니다(float)\n",
    "    3. return: 세션에 전달할 구성입니다(tf 개체)\n",
    "    \"\"\"\n",
    "    device = str(device)\n",
    "    config = tf.compat.v1.ConfigProto() \n",
    "    config.allow_soft_placement = True # 선택한 장치가 없으면 다른 장치로 대체\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 장치를 처리하는 텐서플로우 세션을 시작합니다.\n",
    "    이 부분은 미리 인식될 메모리의 비율입니다.\n",
    "    \n",
    "    1. return: configured tf.Session\n",
    "    \"\"\"\n",
    "    return(tf.compat.v1.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id): # 경로를 새로 만들어서 결과물(그래프)을 저장한다.\n",
    "    # sw = get_summary_writer(tf.compat.v1.Session(device='1'), \"~/.logs_tensorboard/\", \"wavception\", \"V1\") \n",
    "    \"\"\"\n",
    "    For Tensorboard reporting\n",
    "    1. session: opened tensorflow session (tf.Session)\n",
    "    2. logs_path: 텐서보드가 로그를 찾는 경로입니다. (str)\n",
    "    3. project_id: 보고용 프로젝트 이름입니다. (str)\n",
    "    4. version_id: 보고용 버전 이름입니다.(str)\n",
    "    5. return summary_writer: the tensorboard writer\n",
    "    \"\"\"\n",
    "    path = os.path.join(logs_path,\"{}_{}\".format(project_id, version_id)) # '~/.logs_tensorboard/wavception_V1'\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path) # 전체 디렉터리 트리를 삭제합니다\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def) #  path에 그래프(graph_def) 생성\n",
    "    \n",
    "    return(summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/.logs_tensorboard/wavception_V1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sw = get_summary_writer(sess, \"~/.logs_tensorboard/\", \"wavception\", \"V1\")\n",
    "path = os.path.join(\"~/.logs_tensorboard/\",\"{}_{}\".format(\"wavception\", \"V1\")) # \n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7dadd066-bd8e-4902-939d-300993467c67",
    "_uuid": "233bef658d360ebf7c9c6f623925615c56ec727b"
   },
   "source": [
    "## Paths management module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db84f1ec-e69d-47b6-9bc2-6916a224e905",
    "_uuid": "3bba8797dc146f2a51bc6887aa3d60831745425d"
   },
   "source": [
    "경로를 처리할 모듈입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef abc(x):\\n    def ab(*arg, **kwargs)\\n        return x(*arg, **kwargs)\\n    return ab\\n    \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def abc(x):\n",
    "    def ab(*arg, **kwargs)\n",
    "        return x(*arg, **kwargs)\n",
    "    return ab\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "98e21f2b-673c-44d3-a156-56278ebe0054",
    "_uuid": "ac2c7e2219c90972ed163a2ce50c2af3c634f8be"
   },
   "outputs": [],
   "source": [
    "# Common paths\n",
    "def _norm_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력을 정규화하는 데 사용하기 위한 데코레이터 함수입니다.\n",
    "    슬래시/백슬래시 windows 케이스를 수정하는 데 유용합니다.\n",
    "    \"\"\"\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    \n",
    "    return normalize_path\n",
    "\n",
    "\n",
    "def _assure_path_exists(path): # assure : 확신\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력 여부를 확인하기 위한 데코레이터 함수입니다.\n",
    "    fixing the slash/backslash windows cases.\n",
    "    \"\"\"\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p=path(*args, **kwargs)\n",
    "        \n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    \n",
    "    return assure_exists\n",
    "\n",
    "\n",
    "def _is_output_path(path):\n",
    "    \"\"\"\n",
    "    출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "\n",
    "def _is_input_path(path):\n",
    "    \"\"\"\n",
    "    입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"./input/train/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"./input/test/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"../working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"../working/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee43ab62-3c4a-40dc-9f18-efb0c114505d",
    "_uuid": "fb0647c5bf761a85cfbfc98017dfc428cad260f4"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7001ab0b-20f0-44ad-abc9-54c855232c53",
    "_uuid": "46742e27457bae13221a6dd2983aeb05c59b7aaa"
   },
   "source": [
    "일반적인 범용 유틸리티입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c38d1870-b7c4-453e-bf94-1d6226fbe8b8",
    "_uuid": "ca100ad49d05f067cd4c96636a687563581f73d8"
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1): # iterable=filepaths, n =1000\n",
    "    l = len(iterable)# 72000\n",
    "    for ndx in range(0, l, n): # ndx = 1000, 2000, ..., 72000\n",
    "        yield iterable[ndx:min(ndx + n, l)] # filepaths[1000:2000], filepaths[2000:3000], ..., filepaths[71000:72000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4cf6e246-a187-456d-9b32-4885babd562f",
    "_uuid": "2d0cb1612507e8edcf3752cb3411b4836f6ec800"
   },
   "source": [
    "## Data Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d5b73ee-5261-4ada-8ca1-3bf5a31af487",
    "_uuid": "666ca8a8a9f96b9284d8efa3b5d0f5617661c399"
   },
   "source": [
    "Data handling tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Temp/ipykernel_8536/2859869491.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8536/2859869491.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilepaths\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mwavs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_wav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# map(+1해주는 함수/조건, 반복)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8536/3694018068.py\u001b[0m in \u001b[0;36mread_wav\u001b[1;34m(filepath, pad)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;36m3.\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m표본과\u001b[0m \u001b[0m목표\u001b[0m \u001b[0m변수\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# '_background_noise_'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '.'"
     ]
    }
   ],
   "source": [
    "filepath = './input/train/train/audio/_background_noise_/exercise_bike.wav'\n",
    "sample_rate, x = wavfile.read(filepath)\n",
    "target = os.path.split(os.path.split(filepath)[0])[1] # '_background_noise_'\n",
    "\n",
    "for filepaths in batching(filepath, 1000):\n",
    "    wavs, targets = zip(*list(map(read_wav, filepaths))) # map(+1해주는 함수/조건, 반복)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Temp/ipykernel_8536/3694018068.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.        ,  0.        , ..., -0.02764893,\n",
       "        -0.01760864,  0.00912476]),\n",
       " '_background_noise_')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = './input/train/train/audio/_background_noise_/exercise_bike.wav'\n",
    "read_wav(filepath, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/tr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8536/2967134095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilepaths\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mwavs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# map(+1해주는 함수/조건, 반복)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8536/3694018068.py\u001b[0m in \u001b[0;36mread_wav\u001b[1;34m(filepath, pad)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;36m3.\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m표본과\u001b[0m \u001b[0m목표\u001b[0m \u001b[0m변수\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# '_background_noise_'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/tr'"
     ]
    }
   ],
   "source": [
    "for filepaths in batching(filepath, n=10):\n",
    "    wavs, targets = zip(*list((read_wav(filepaths, pad=False)))) # map(+1해주는 함수/조건, 반복)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "99da70b7-1f49-41f5-bd6b-268429c2d401",
    "_uuid": "87488aa067d32f457072b5816b8f96a45e1add11"
   },
   "outputs": [],
   "source": [
    "# Data tools\n",
    "def read_wav(filepath, pad=True):\n",
    "    \"\"\"\n",
    "    wav 파일의 파일 경로를 지정하면 이 함수는 파일을 읽고 정규화하고 패드를 채웁니다.\n",
    "    16k개의 샘플을 가지고 있는지 확인합니다.\n",
    "    1. filepath: wav 파일의 기존 파일 경로입니다. (str)\n",
    "    2. pad: 패딩이 필요합니까? (bool)\n",
    "    3. returns: 표본과 목표 변수 (tuple of (np.array, str))\n",
    "    \"\"\"\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1] # '_background_noise_'\n",
    "    assert sample_rate==16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode=\"constant\")/32768, target\n",
    "    else:\n",
    "        return x/32768, target\n",
    "\n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False): \n",
    "    # get_batcher(testing_list, 64, le_classes)\n",
    "    # list_of_paths = './input/train/train/audio/**/*.wav', batchsize=1000/0, label_encoder = LabelEncoder().fit(cardinal_classes)\n",
    "    \"\"\" \n",
    "    배치 목록이 지정된 배치 생성기를 작성합니다.\n",
    "    1. list_of_paths: 형식 요소가 있는 튜플 리스트입니다. (filepath, target) (list)\n",
    "    2. batch_size: size of the batch (int)\n",
    "    3. label_encoder: fitted LabelEncoder (sklearn.LabelEncoder|optional)\n",
    "    4. scoring: 대상을 고려해야 합니까? (bool)\n",
    "    5. returns: batch generator\n",
    "    \"\"\"\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths))) # map(+1해주는 함수/조건, 반복)\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths # np.row_stack() = np.vstack()\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1472be2-c57a-41be-bf61-c5dea64e9c0c",
    "_uuid": "167d8606f98b87258078ef99d89bf7cc1d84c724"
   },
   "source": [
    "## Architecture building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a299b242-fd42-4cbf-8181-2bdbd9fa7c3a",
    "_uuid": "fa4997b17d264980689f988e1a50519206d13246"
   },
   "source": [
    "Inception-1D(일명 wavception)는 이 문제를 해결하기 위해 몇 주 전에 설계한 모듈입니다. 그것은 규칙적인 컨볼루션 뉴럴 네트의 성능을 상당히 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf.compat.v1.disable_eager_execution()\\n\\nholder1 = tf.compat.v1.placeholder(dtype=tf.float32)\\nholder2 = tf.compat.v1.placeholder(dtype=tf.float32)\\nholder3 = tf.compat.v1.placeholder(dtype=tf.float32)\\n \\nv1 = 5\\nv2 = 10\\nv3 = 3\\n \\n# 함수    \\nret_val = holder1 * holder2 + holder3 # <tf.Tensor \\'add:0\\' shape=<unknown> dtype=float32>\\n\\n# 값 할당\\nfeed_dict = {holder1: v1, holder2: v2, holder3: v3}\\n\\n# 값계산을 위한 세션 사용\\ndef get_tensorflow_configuration(device=\"0\", memory_fraction=1): # memory_fraction=1 : 100% 사용 # configuration : 구성\\n    device = str(device)\\n    config = tf.compat.v1.ConfigProto() \\n    config.allow_soft_placement = True # 선택한 장치가 없으면 다른 장치로 대체\\n    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\\n    config.gpu_options.visible_device_list = device\\n    return(config)\\n\\n\\ndef start_tensorflow_session(device=\"0\", memory_fraction=1):\\n    return(tf.compat.v1.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\\n\\nsess = start_tensorflow_session(device=\"1\")\\n\\nresult = sess.run(ret_val, feed_dict=feed_dict)\\n \\nprint(result)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "holder1 = tf.compat.v1.placeholder(dtype=tf.float32)\n",
    "holder2 = tf.compat.v1.placeholder(dtype=tf.float32)\n",
    "holder3 = tf.compat.v1.placeholder(dtype=tf.float32)\n",
    " \n",
    "v1 = 5\n",
    "v2 = 10\n",
    "v3 = 3\n",
    " \n",
    "# 함수    \n",
    "ret_val = holder1 * holder2 + holder3 # <tf.Tensor 'add:0' shape=<unknown> dtype=float32>\n",
    "\n",
    "# 값 할당\n",
    "feed_dict = {holder1: v1, holder2: v2, holder3: v3}\n",
    "\n",
    "# 값계산을 위한 세션 사용\n",
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1): # memory_fraction=1 : 100% 사용 # configuration : 구성\n",
    "    device = str(device)\n",
    "    config = tf.compat.v1.ConfigProto() \n",
    "    config.allow_soft_placement = True # 선택한 장치가 없으면 다른 장치로 대체\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    return(tf.compat.v1.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "sess = start_tensorflow_session(device=\"1\")\n",
    "\n",
    "result = sess.run(ret_val, feed_dict=feed_dict)\n",
    " \n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "5f9d3b17-e5b8-4801-a91b-bf9fce956b84",
    "_uuid": "b2e0ccb28bc9a730958a11c6ad35da321ff33db9"
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name=\"batch_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                            decay=self.momentum,\n",
    "                                            updates_collections=None,\n",
    "                                            epsilon=self.epsilon,\n",
    "                                            scale=True,\n",
    "                                            is_training=train,\n",
    "                                            scope=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):  # depth=1,2,3,4\n",
    "    \"\"\"\n",
    "    inception_1d(x=self.placeholders.wav_in=batch_x=get_batcher=train_list=,\n",
    "                            is_train=self.placeholders.is_train=bool, \n",
    "                             norm_function=BatchNorm=tf.contrib.layers.batch_norm(x), \n",
    "                             activ_function=tf.nn.relu, depth=1,\n",
    "                             name=\"Inception_1_1\")\n",
    "                             \n",
    "    Inception 1D 모듈 구현입니다.\n",
    "    1. x: 현재 모듈에 입력합니다. (4D tensor with channels-last)\n",
    "    2. is_train: BatchNormalization 동작을 제어하기 위한 부울 자리 표시자가 되려고 합니다. (0D tensor)\n",
    "    3. depth: 네트워크의 깊이를 선형적으로 제어합니다.(int)\n",
    "    4. norm_function: 정규화 클래스입니다. (same format as the BatchNorm class above)\n",
    "    5. activ_function: 활성화함수 (e.g. tf.nn.relu) \n",
    "    6. name: 변수 범위의 이름입니다. (str)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name=\"norm_input\")(x, train=is_train) # BatchNorm(name='norm_input')(x, train=s)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train) # BatchNorm\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")  # tf.nn.relu\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0210bf0-d88f-4bbd-8be8-11013fcc4b32",
    "_uuid": "87e5f1456e46cc5295acb535e761ba0f4cdc60cd"
   },
   "source": [
    "## Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\doing_the_dishes.wav',\n",
       " 'input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\dude_miaowing.wav',\n",
       " 'input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\exercise_bike.wav',\n",
       " 'input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\pink_noise.wav',\n",
       " 'input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\running_tap.wav',\n",
       " 'input\\\\train\\\\train\\\\audio\\\\_background_noise_\\\\white_noise.wav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths_noise = glob.glob(os.path.join(get_train_audio_path(), \"_background_noise_\", \"*.wav\")) \n",
    "filepaths_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda i: i, [1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Temp/ipykernel_8536/3694018068.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6390371,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise))) # x= filepaths_noise\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "aeec049b-d435-44d9-9c5f-ef57b2a6c1b3",
    "_uuid": "b779ec62114e4036225b2f62ea3a9bcab013e143"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Temp/ipykernel_8276/3277725824.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ...,  0.02363595,\n",
       "       -0.16235002, -0.09919803])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성 및 제공된 소음 추가입니다.\n",
    "filepaths_noise = glob.glob(os.path.join(get_train_audio_path(), \"_background_noise_\", \"*.wav\")) \n",
    "# filepaths_noise = './input/train/train/audio/_background_noise_/*.wav'\n",
    "\n",
    "# _background_noise_에 있는 노이즈를 모두 합친다.\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise))) # (6390371,), x= filepaths_noise\n",
    "# [x1.wav/32768, x2.wav/32768, x3.wav/32768, ...]\n",
    "# 노이즈의 내림차순으로 한번 합친다.\n",
    "noise = np.concatenate([noise, noise[::-1]]) # [x1/32768, x2/32768, x3/32768, ... , x3/32768, x2/32768, x1/32768] - > (12780742,)\n",
    "\n",
    "# 실제 있는 blue/pink.. noise를 합치고 분수화 한다. + 작업하나 더 한 후 위의 노이즈와 합친다.\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)]) # (3360000,)\n",
    "\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise)) # [w/k, b/k, p/k, b/k, v/k, z/k ]\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])  # [w/k, b/k, p/k, b/k, v/k, z/k, (w/k+z/k)/2, ... ]\n",
    "all_noise = np.concatenate([noise, synthetic_noise]) # [x1/32768, x2/32768, x3/32768, ... , x3/32768, x2/32768, x1/32768, w/k, b/k, p/k, b/k, v/k, z/k, (w/k+z/k)/2, ... ]\n",
    "all_noise.shape # (19500742,)\n",
    "all_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)])\n",
    "synthetic_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12780742,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na= [1,2,3,4]\\nb = a[::-1]\\nc = np.concatenate([a, b])\\nc # array([1, 2, 3, 4, 4, 3, 2, 1])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a= [1,2,3,4]\n",
    "b = a[::-1]\n",
    "c = np.concatenate([a, b])\n",
    "c # array([1, 2, 3, 4, 4, 3, 2, 1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "f579e3ad-a7ee-4e0c-a677-1a96fea8b71e",
    "_uuid": "022d18f46ce8415e3a4f3e66a86b3f55f41d3860"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▉                                       | 3940/8000 [00:04<00:04, 866.10it/s]C:\\Users\\HOME\\AppData\\Local\\Temp/ipykernel_8276/3625355955.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:07<00:00, 1069.61it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "\n",
    "path = get_silence_path() # \"../working/silence\" 출력경로\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) # 읽기 전용 파일 시스템으로 인해 kaggle 커널에서 실패합니다.\n",
    "\n",
    "# 기존 음성파일에 더해줄 노이즈를 추출한다.(절반은 noise, 절반은 synthetic_noise로)     \n",
    "for noise_clip_no in tqdm(range(8000)): # 진행표시바\n",
    "    if noise_clip_no<=4000:\n",
    "        idx = np.random.randint(0, len(noise)-16000) # (0, 12,780,742-16,000) 중 하나 추출\n",
    "        clip = noise[idx:(idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(synthetic_noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    \n",
    "    # wavfile.write(파일명, rate, 데이터=분수화)\n",
    "    wavfile.write(os.path.join(path, \"{0:04d}.wav\".format(noise_clip_no)), 16000, \n",
    "                               ((32767*clip/np.max(np.abs(clip))).astype(np.int16))) \n",
    "    # wavfile.write(filename, rate, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\working\\\\silence\\\\7999.wav'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음성파일과 노이즈 합치기\n",
    "\n",
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True) # filepaths = './input/train/train/audio/**/*.wav'\n",
    "# 파라미터 recursive=True 로 설정하고 ** 로 작성하면 하위 폴더에도 접근할 수 있습니다\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True) # \"../working/silence\"\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths)) # filter(조건 함수, 순회 가능한 데이터) : fp에 filepaths 대입\n",
    "filepaths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "c4f36041-b721-44cc-81ed-0a8b39bd9eed",
    "_uuid": "5b367716f0abfbca6d05ed7aea096b9e82df0b53",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59088"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 리스트\n",
    "validation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines() # './input/train/train/validation_list.txt'\n",
    "validation = []\n",
    "for val in validation_list:\n",
    "    validation.append(val.replace('/', '\\\\'))\n",
    "    \n",
    "# test 리스트\n",
    "test_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines() # './input/train/train/testing_list.txt'\n",
    "test = []\n",
    "for ts in test_list:\n",
    "    test.append(ts.replace('/', '\\\\'))\n",
    "\n",
    "validation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation)) # './input/train/train/audio/vl1.wav, ...'\n",
    "testing_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test)) # './input/train/train/audio/t1.wav, ...'\n",
    "\n",
    "# train에서 validation과 test의 리스트를 제거\n",
    "training_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist() # np.setdiff1d(차집합)\n",
    "len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvalidation_list124 = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines() # \\'./input/train/train/validation_list.txt\\'\\nvalidation_list12 = []\\nfor i in validation_list124:\\n    validation_list12.append(i.replace(\\'/\\', \\'\\\\\\'))\\n\\nvalidation_list12\\n\\nvalidation_list13 = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list12)) # \\'./input/train/train/audio/vl1.wav, ...\\'\\nvalidation_list13'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "validation_list124 = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines() # './input/train/train/validation_list.txt'\n",
    "validation_list12 = []\n",
    "for i in validation_list124:\n",
    "    validation_list12.append(i.replace('/', '\\\\'))\n",
    "\n",
    "validation_list12\n",
    "\n",
    "validation_list13 = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list12)) # './input/train/train/audio/vl1.wav, ...'\n",
    "validation_list13'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfilepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True) # filepaths = \\'./input/train/train/audio/**/*.wav\\'\\n# 파라미터 recursive=True 로 설정하고 ** 로 작성하면 하위 폴더에도 접근할 수 있습니다\\nfilepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True) # \"../working/silence\"\\nfilepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths)) # \\'_background_noise_\\'를 제외# filter(조건 함수, 순회 가능한 데이터) : fp에 filepaths 대입\\nfilepaths\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True) # filepaths = './input/train/train/audio/**/*.wav'\n",
    "# 파라미터 recursive=True 로 설정하고 ** 로 작성하면 하위 폴더에도 접근할 수 있습니다\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True) # \"../working/silence\"\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths)) # '_background_noise_'를 제외# filter(조건 함수, 순회 가능한 데이터) : fp에 filepaths 대입\n",
    "filepaths\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\na = ['c']\\nb = ['d']\\na+b # ['c', 'd']\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a = ['c']\n",
    "b = ['d']\n",
    "a+b # ['c', 'd']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "0840a4b4-2103-4ed0-8046-d6ebf91a8fe9",
    "_uuid": "9b036b76d0e7e4d24b749846f4aec42a213aa505"
   },
   "outputs": [],
   "source": [
    "random.seed(655321)\n",
    "random.shuffle(filepaths)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(testing_list)\n",
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filepaths) # 72721\n",
    "len(validation_list) # 6798\n",
    "len(testing_list) # 6835\n",
    "len(training_list) # 59088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "a35f7c09-1ebf-4d84-adf8-5ad3d118f0fb",
    "_uuid": "c8b9d3d50116c18af5d3c5d50ad76f2dd0612078",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 빠른 단위 테스트입니다.\n",
    "# 파일 수와 파일 일관성을 테스트합니다.\n",
    "assert all(map(lambda fp: os.path.splitext(fp)[1]==\".wav\", filepaths))\n",
    "assert len(filepaths)==64727 - 6 + 8000\n",
    "assert len(training_list) == len(filepaths) - len(validation_list) - len(testing_list) \n",
    "assert len(validation_list) == 6798\n",
    "assert len(testing_list) == 6835\n",
    "\n",
    "# 파일 존재 여부를 테스트합니다.\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\n",
    "assert set(validation_list + testing_list + training_list) == set(filepaths)\n",
    "\n",
    "# 집합 간에 겹치지 않도록 테스트합니다.\n",
    "assert len(np.intersect1d(validation_list, testing_list))==0 # np.intersect1d(교집합)\n",
    "assert len(np.intersect1d(training_list, testing_list))==0\n",
    "assert len(np.intersect1d(training_list, validation_list))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "5c17af42-214c-4dab-b066-d7a0c6acac13",
    "_uuid": "3852dcc9ef44bc2841eecf65361d7b6f95e43b5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'no': 2375,\n",
       "         'yes': 2377,\n",
       "         'stop': 2380,\n",
       "         'nine': 2364,\n",
       "         'left': 2353,\n",
       "         'dog': 1746,\n",
       "         'wow': 1745,\n",
       "         'up': 2375,\n",
       "         'one': 2370,\n",
       "         'six': 2369,\n",
       "         'zero': 2376,\n",
       "         'two': 2373,\n",
       "         'sheila': 1734,\n",
       "         'tree': 1733,\n",
       "         'silence': 8000,\n",
       "         'four': 2372,\n",
       "         'marvin': 1746,\n",
       "         'bed': 1713,\n",
       "         'right': 2367,\n",
       "         'seven': 2377,\n",
       "         'cat': 1733,\n",
       "         'eight': 2352,\n",
       "         'five': 2357,\n",
       "         'on': 2367,\n",
       "         'happy': 1742,\n",
       "         'off': 2357,\n",
       "         'three': 2356,\n",
       "         'go': 2372,\n",
       "         'down': 2359,\n",
       "         'bird': 1731,\n",
       "         'house': 1750})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes processing\n",
    "cardinal_classes = list(set(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))) \n",
    "# ['stop', 'off', 'up', 'zero', 'bed', ... 'silence','three']\n",
    "le_classes = LabelEncoder().fit(cardinal_classes)\n",
    "Counter(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cardinal_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "9553bb5e-fb15-4a37-9876-8f4685b3076f",
    "_uuid": "791fd120463dd67b4255de43eb64a0af75655256"
   },
   "outputs": [],
   "source": [
    "# Quick Unit-Tests\n",
    "# Test data preparation\n",
    "_gen_test = get_batcher(filepaths, 1000) # filepaths = './input/train/train/audio/**/*.wav' # wav, target\n",
    "batch_a_wav, batch_a_target = next(_gen_test) # ex) [[값], [값],..], [['bed'], ['no']]\n",
    "batch_b_wav, batch_b_target = next(_gen_test) \n",
    "_gen_test_le = get_batcher(filepaths, 1000, label_encoder=le_classes)\n",
    "batch_le_wav, batch_le_target = next(_gen_test_le) # ex) [[4], [23], [31] \n",
    "\n",
    "# 배치 행렬 모양 일관성을 검정합니다.\n",
    "assert batch_a_wav.shape == (1000, 16000, 1)\n",
    "assert batch_le_wav.shape == (1000, 16000, 1)\n",
    "assert batch_a_wav.shape == batch_b_wav.shape == batch_le_wav.shape\n",
    "\n",
    "# 배치 재현성을 테스트합니다.\n",
    "assert np.sum(np.abs(batch_a_wav-batch_b_wav)) != 0\n",
    "assert len(batch_a_target) == len(batch_b_target) == len(batch_le_target)\n",
    "assert any(batch_a_target != batch_b_target)\n",
    "\n",
    "# 테스트 클래스 레이블 인코더입니다.\n",
    "assert all(batch_le_target == np.expand_dims(le_classes.transform(np.squeeze(batch_a_target)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00],\n",
       "        [-4.57763672e-04],\n",
       "        [-4.57763672e-04],\n",
       "        ...,\n",
       "        [-6.40869141e-04],\n",
       "        [-5.79833984e-04],\n",
       "        [-5.79833984e-04]],\n",
       "\n",
       "       [[ 0.00000000e+00],\n",
       "        [ 1.22070312e-04],\n",
       "        [-3.05175781e-05],\n",
       "        ...,\n",
       "        [-2.74658203e-04],\n",
       "        [-3.66210938e-04],\n",
       "        [-1.52587891e-04]],\n",
       "\n",
       "       [[ 6.10351562e-05],\n",
       "        [-3.05175781e-05],\n",
       "        [ 2.13623047e-04],\n",
       "        ...,\n",
       "        [-3.35693359e-04],\n",
       "        [-3.96728516e-04],\n",
       "        [-3.05175781e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.70898438e-03],\n",
       "        [-2.74658203e-03],\n",
       "        [-2.41088867e-03],\n",
       "        ...,\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[-1.43432617e-03],\n",
       "        [-1.92260742e-02],\n",
       "        [-2.43530273e-02],\n",
       "        ...,\n",
       "        [ 1.60522461e-02],\n",
       "        [ 1.59606934e-02],\n",
       "        [ 1.48620605e-02]],\n",
       "\n",
       "       [[-1.19018555e-03],\n",
       "        [-1.98364258e-03],\n",
       "        [-2.04467773e-03],\n",
       "        ...,\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_le_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naa = iter([1,2,3])\\nxx= next(aa) # 1\\nyy= next(aa) # 2\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "aa = iter([1,2,3])\n",
    "xx= next(aa) # 1\n",
    "yy= next(aa) # 2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwavs, targets = zip(*list(map(read_wav, 'input\\\\train\\\\train\\\\audio\\\\bed\\\\3903b558_nohash_0.wav',)))\\nwavs \\n# (array([-0.00073242, -0.00198364, -0.00137329, ...,  0.00164795,\\n#          0.00189209,  0.00216675]),)\\ntargets\\n# ('bed',)\\nnp.expand_dims(np.row_stack(wavs), 2)\\n# array([[[-0.00073242],\\n#        [-0.00198364],\\n#        [-0.00137329],\\n#        ...,\\n#        [ 0.00164795],\\n#        [ 0.00189209],\\n#        [ 0.00216675]]])\\n\\nnp.row_stack(targets)\\n# array([['bed']], dtype='<U3')\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "wavs, targets = zip(*list(map(read_wav, 'input\\\\train\\\\train\\\\audio\\\\bed\\\\3903b558_nohash_0.wav',)))\n",
    "wavs \n",
    "# (array([-0.00073242, -0.00198364, -0.00137329, ...,  0.00164795,\n",
    "#          0.00189209,  0.00216675]),)\n",
    "targets\n",
    "# ('bed',)\n",
    "np.expand_dims(np.row_stack(wavs), 2)\n",
    "# array([[[-0.00073242],\n",
    "#        [-0.00198364],\n",
    "#        [-0.00137329],\n",
    "#        ...,\n",
    "#        [ 0.00164795],\n",
    "#        [ 0.00189209],\n",
    "#        [ 0.00216675]]])\n",
    "\n",
    "np.row_stack(targets)\n",
    "# array([['bed']], dtype='<U3')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed02eca4-76ee-4b40-89a4-a853ddd74143",
    "_uuid": "671cb5ffa15b6fd8e549df8e0a6dcdb5b21a64f8"
   },
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c67ad8f-80e3-43f9-a358-d352b17e8dbf",
    "_uuid": "24889480a844029116c9c9880611bc3fafd7d9bf"
   },
   "source": [
    "Here it comes, WavCeption design"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    name = ''\n",
    "\n",
    "    korean = 0\n",
    "\n",
    "    english = 0\n",
    "\n",
    "    math = 0\n",
    "\n",
    "    def __init__(self, name, kor, eng, math):\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "        self.korean = kor\n",
    "\n",
    "        self.english = eng\n",
    "\n",
    "        self.math = math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Student at 0x1f345fdf9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Student('홍길동', 80, 85, 75)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ab30f80-6bff-43bd-9280-8aaa50326283",
    "_uuid": "53e3de8a3ad9a1bd08746065d4d8bb6fab648615",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 동적 할당\n",
    "class NameSpacer:\n",
    "    def __init__(self, **kwargs): # {\"wav_in\": wav_in, \"target\": target, \"is_train\": is_train, \"acc_dev\": acc_dev, \"loss_dev\": loss_dev}\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "# 모델\n",
    "class Architecture: \n",
    "    # net = Architecture(self, class_cardinality=len(cardinal_classes), name=\"wavception\")\n",
    "    # cardinal_classes = list(set(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))) # ['no','bed',...]\n",
    "    # len(cardinal_classes) = 31\n",
    "    def __init__(self, class_cardinality, seq_len=16000, name=\"architecture\"):\n",
    "        self.seq_len = seq_len # 16,000\n",
    "        self.class_cardinality = class_cardinality # 31\n",
    "        self.name = name # wavception\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.define_computation_graph()\n",
    "        \n",
    "        # 별칭\n",
    "        self.ph = self.placeholders\n",
    "        self.op = self.optimizers\n",
    "        self.summ = self.summaries\n",
    "\n",
    "    def define_computation_graph(self):\n",
    "        # Reset graph\n",
    "        tf.reset_default_graph()\n",
    "        self.placeholders = NameSpacer(**self.define_placeholders()) # self.__dict__.update(define_placeholders()) = NameSpacer().Placeholders/wav_in/.target/...\n",
    "        self.core_model = NameSpacer(**self.define_core_model()) # NameSpacer().Core_Model/output\n",
    "        self.losses = NameSpacer(**self.define_losses()) # NameSpacer().softmax_ce\n",
    "        self.optimizers = NameSpacer(**self.define_optimizers()) # NameSpacer().op\n",
    "        self.summaries = NameSpacer(**self.define_summaries()) # NameSpacer().acc/.loss/.train_performance_scalar/.dev_performance_scalar\n",
    "\n",
    "    def define_placeholders(self):\n",
    "        with tf.variable_scope(\"Placeholders\"):\n",
    "            wav_in = tf.placeholder(dtype=tf.float32, shape=(None, self.seq_len, 1), name=\"wav_in\")\n",
    "            is_train = tf.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n",
    "            target = tf.placeholder(dtype=tf.int32, shape=(None, 1), name=\"target\")\n",
    "            acc_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"acc_dev\")\n",
    "            loss_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"loss_dev\")\n",
    "            return({\"wav_in\": wav_in, \"target\": target, \"is_train\": is_train, \"acc_dev\": \n",
    "                    acc_dev, \"loss_dev\": loss_dev})\n",
    "        \n",
    "    def define_core_model(self):\n",
    "        with tf.variable_scope(\"Core_Model\"):\n",
    "            x = inception_1d(x=self.placeholders.wav_in, is_train=self.placeholders.is_train, \n",
    "                             norm_function=BatchNorm, activ_function=tf.nn.relu, depth=1,\n",
    "                             name=\"Inception_1_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_1_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_3\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_2\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_3\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_4\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_5\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_6\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_7\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_8\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_9\")\n",
    "            x = tf.contrib.layers.flatten(x)\n",
    "            x = tf.layers.dense(BatchNorm(name=\"bn_dense_1\")(x,train=self.placeholders.is_train),\n",
    "                                128, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"dense_1\")\n",
    "            output = tf.layers.dense(BatchNorm(name=\"bn_dense_2\")(x,train=self.placeholders.is_train),\n",
    "                                self.class_cardinality, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"output\")\n",
    "            return({\"output\": output})\n",
    "        \n",
    "    def define_losses(self):\n",
    "        with tf.variable_scope(\"Losses\"):\n",
    "            softmax_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.squeeze(self.placeholders.target), \n",
    "                                                                        logits=self.core_model.output,\n",
    "                                                                        name=\"softmax\")\n",
    "            return({\"softmax\": softmax_ce})\n",
    "\n",
    "    def define_optimizers(self):\n",
    "        with tf.variable_scope(\"Optimization\"):\n",
    "            op = self.optimizer.minimize(self.losses.softmax)\n",
    "            return({\"op\": op})\n",
    "\n",
    "    def define_summaries(self):\n",
    "        with tf.variable_scope(\"Summaries\"):\n",
    "            ind_max = tf.squeeze(tf.cast(tf.argmax(self.core_model.output, axis=1), tf.int32))\n",
    "            target = tf.squeeze(self.placeholders.target)\n",
    "            acc = tf.reduce_mean(tf.cast(tf.equal(ind_max, target), tf.float32)) # 정확도\n",
    "            loss = tf.reduce_mean(self.losses.softmax) \n",
    "            train_scalar_probes = {\"accuracy\": acc, \n",
    "                                   \"loss\": loss}\n",
    "            train_performance_scalar = [tf.summary.scalar(k, tf.reduce_mean(v), family=self.name) \n",
    "                                        for k, v in train_scalar_probes.items()]\n",
    "            train_performance_scalar = tf.summary.merge(train_performance_scalar)\n",
    "\n",
    "            dev_scalar_probes = {\"acc_dev\": self.placeholders.acc_dev, \n",
    "                                 \"loss_dev\": self.placeholders.loss_dev}\n",
    "            dev_performance_scalar = [tf.summary.scalar(k, v, family=self.name) for k, v in dev_scalar_probes.items()]\n",
    "            dev_performance_scalar = tf.summary.merge(dev_performance_scalar)\n",
    "            return({\"accuracy\": acc, \"loss\": loss, \"s_tr\": train_performance_scalar, \"s_de\": dev_performance_scalar})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b390b59e-0a78-4ff7-9b7d-fc0b48c7b3dd",
    "_uuid": "e8dec0fa842ab5f693daf729900f461145a8355f"
   },
   "source": [
    "## Run model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d586dc1-2f02-4669-8aca-5010ed9d2a1a",
    "_uuid": "9d79ca62dd150ac46a471492ce6156b265e9ef07"
   },
   "source": [
    "오래 걸리지 않으려면 GPU를 사용하여 모델을 실행해야 합니다. 또한 예측하기 위해 네트워크를 중지할 시기를 결정해야 합니다. 타이탄 엑스 파스칼에서 12시간이나 걸렸어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a226088d-ecd9-4070-8893-de1ecc90938f",
    "_uuid": "bd4220c1d4ba2b9c20e0f51c226387217109b692",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Architecture(class_cardinality=len(cardinal_classes), name=\"wavception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ef8b85d6-271c-434a-b886-447e6d57c1b6",
    "_uuid": "dea3a0c128e64b3e8680b51ae0486c4ce0031e79",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = start_tensorflow_session(device=\"1\")\n",
    "sw = get_summary_writer(sess, \"~/.logs_tensorboard/\", \"wavception\", \"V1\") # 여기서 텐서보드 로그 경로를 조정합니다.\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2575da3e-f8b4-4a83-beba-f4683cf09cb1",
    "_uuid": "4f0503ed3dffd436ff81caeefeac880b95167396",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer()) # 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c4198ebd-bfbf-4c37-8370-95a37f73f5fa",
    "_uuid": "ee203cc482466c4f133ff83161bcd871c626bc5c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7872b624-0a21-45e6-b5d1-47323a69e8d3",
    "_uuid": "34ba4ec269007f8102fe6dff142763e10d29902f",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(50000):\n",
    "    random.shuffle(training_list)\n",
    "    batcher = get_batcher(training_list, 16, le_classes)\n",
    "    for i, (batch_x, batch_y) in enumerate(batcher):\n",
    "        # net.ph.wav_in + .target+.is_train으로 [net.op.op, net.losses.softmax...]를 구함 \n",
    "        _, loss, acc, s = sess.run([net.op.op, net.losses.softmax, net.summ.accuracy, net.summ.s_tr],\n",
    "                                 feed_dict={net.ph.wav_in: batch_x, # Architecture().placeholder.wav_in\n",
    "                                            net.ph.target: batch_y, \n",
    "                                            net.ph.is_train: True})\n",
    "        print(\"[{0:04d}|{1:04d}] Accuracy train: {2:.2f}%\".format(epoch, i, acc*100))\n",
    "        sw.add_summary(s, c)\n",
    "        \n",
    "        if c%1000==0: # Validation\n",
    "            accuracies_dev=[]\n",
    "            losses_dev=[]\n",
    "            batcher = get_batcher(validation_list, 16, le_classes)\n",
    "            for i, (batch_x, batch_y) in enumerate(batcher):\n",
    "                acc, loss= sess.run([net.summ.accuracy, net.summ.loss], \n",
    "                               feed_dict={net.ph.wav_in: batch_x, \n",
    "                                          net.ph.target: batch_y, \n",
    "                                          net.ph.is_train: False})\n",
    "                accuracies_dev.append(acc)\n",
    "                losses_dev.append(loss)\n",
    "            s = sess.run(net.summ.s_de, feed_dict={net.ph.acc_dev: np.mean(accuracies_dev),\n",
    "                                                   net.ph.loss_dev: np.mean(losses_dev)})\n",
    "            sw.add_summary(s, c)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a499d252-39d4-4262-9d3e-b0a5de05e44b",
    "_uuid": "cbf30b73e48e0f832ce07358ae4aa5a1e6b2bf22"
   },
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e4679982-80ae-4906-b9ed-820b5050d6ce",
    "_uuid": "df013bec21566ca6df051b649fa9ad2af886c3fd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "batcher = get_batcher(testing_list, 64, le_classes)\n",
    "# 64단위의 배치 덩어리들에 대한 wav, target을 반환\n",
    "for i, (batch_x, batch_y) in tqdm(enumerate(batcher)):\n",
    "    acc = sess.run(net.summ.accuracy, feed_dict={net.ph.wav_in: batch_x,\n",
    "                                                 net.ph.target: batch_y, \n",
    "                                                 net.ph.is_train: False})\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f13d203-8631-41ad-8db2-c3fb0da16938",
    "_uuid": "5c38203a647bb0b93fd29174eb81a2e3cb4f16ed"
   },
   "source": [
    "## Prediction and submission building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6a67202-a658-46da-9934-555b355f24e9",
    "_uuid": "e2266973295bc652913ad078e14c35ef44e9c702",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_list = glob.glob(os.path.join(get_scoring_audio_path(), \"*.wav\"), recursive=True)\n",
    "# './input/test/test/audio/*.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "91bce141-2bb6-46eb-bff5-9578260a307e",
    "_uuid": "14e7aec6a0c2200191904c1f2f65013d71620813",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batcher = get_batcher(scoring_list, 80, le_classes, scoring=True) \n",
    "# 80단위의 배치 덩어리들에 대한 wav, target을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11015ffb-878c-4451-9688-3f3dbbd5114d",
    "_uuid": "dd967dd2c93fd7dbc867c505b1ba66a108db7805",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fns = []\n",
    "prds = []\n",
    "for i, (batch_x, filepaths) in tqdm(enumerate(batcher)): # 인덱스, 함수1, 함수2 -> 총 3개 가능\n",
    "    pred = sess.run(net.core_model.output, feed_dict={net.ph.wav_in: batch_x, \n",
    "                                                      net.ph.is_train: False})\n",
    "    fns.extend(map(lambda f:os.path.split(f)[1], filepaths))\n",
    "    prds.extend(map(lambda f:np.argmax(pred, axis=1).tolist(), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f188097c-6eb7-40e6-add6-24a3dc4b3cb7",
    "_uuid": "666fb81cce7b16f1f229d2936ef877105f1446a3"
   },
   "source": [
    "참고: 여기에서 알 수 없는 클립 문제를 빠르고 지저분한 방법으로 해결했습니다. 성능은 여전히 양호하지만(최대 76LB), 훨씬 더 현명한 방법이 있습니다;-.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bafc416e-9bcf-46cc-8b7a-ef627dda8220",
    "_uuid": "04c064866c203f7e29c0a43347b7ff29bfe33443",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission storage\n",
    "df=pd.DataFrame({\"fname\":fns, \"label\": prds})\n",
    "df.label = le_classes.inverse_transform(df.label) # .inverse_transform : 본래값으로 되돌린다.\n",
    "df.loc[~df.label.isin([\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\"]), \"label\"] = \"unknown\" # df.loc[행, 열]\n",
    "df.to_csv(os.path.join(get_submissions_path(), \"submission.csv\"), index=False) # \"../working/output/submission.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
