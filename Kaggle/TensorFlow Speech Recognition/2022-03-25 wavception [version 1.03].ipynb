{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d687d4e8",
   "metadata": {
    "_cell_guid": "58ef1a47-96bc-416d-a016-938a494fb1c3",
    "_uuid": "b531642dd4c3a53e20e5f6b9076bf17e9418e1e4"
   },
   "source": [
    "# WavCeption V1: just a 1-D Inception approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0fd99",
   "metadata": {
    "_cell_guid": "e68a3daa-14d7-46d7-a0db-9f80380b9d0f",
    "_uuid": "f597ce3d9e1e9fe818cf0a8e51f6da2404ba5b43"
   },
   "source": [
    "저는 단지 제가 가지고 놀던 작은 장난감을 공유하고 싶었을 뿐인데 **놀라운 결과**를 주었습니다. 지금은 시간이 없기 때문에, 사람들이 어떻게 가지고 놀지 보려고 공유하려고 합니다. :-D. **WavCception V1** 네트워크는 일반 컨볼루션 뉴럴 네트워크에 비해 인상적인 결과를 얻을 수 있는 것으로 보이지만, 이번 경쟁에서는 전처리 및 알려지지 않은 트랙 관리에 많은 노력이 필요한 것으로 보입니다. 이것은 구글의 초기 네트워크를 기반으로 합니다. 같은 아이디어입니다. \n",
    "\n",
    " 저는 몇 주 전에 이러한 모듈들을 캐스케이드로 연결하여 쉽게 1D 인셉션 네트워크를 구축할 수 있도록 구현하는 모듈을 작성했습니다(아래 참조).\n",
    " \n",
    " 아쉽게도 몇 가지 Kaggle의 제약으로 인해 커널 머신에서는 실행되지 않으므로 다운로드하여 자신의 머신에서 실행해 보시기 바랍니다.\n",
    " \n",
    " 너무 고생하지 않고 12시간 동안 모델을 실행함으로써 리더보드에서 0.76을 달성했습니다(로컬 테스트에서는 0.84). 같은 라인의 다른 시험에서는 로컬에서 0.89를 얻었기 때문에 알려지지 않은 클립을 처리하는 방법이 크게 개선되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905c7d4",
   "metadata": {
    "_cell_guid": "dd3e1543-18e2-4be6-b511-5c1e734d2c60",
    "_uuid": "f924854d4d258cd9a7db10eb5566e0bdff085574"
   },
   "source": [
    "## Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52e716d",
   "metadata": {
    "_cell_guid": "cb0f537e-1932-4c45-a4d0-59e7d2caac6b",
    "_uuid": "9d73d1472e8ea2c21b0c70b5f537a74a9c562708"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil # shutil 모듈은 파일과 파일 모음에 대한 여러 가지 고수준 연산을 제공합니다. 특히, 파일 복사와 삭제를 지원하는 함수가 제공됩니다\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm \n",
    "from collections import Counter # Counter('hello world') # Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft # 1차원 이산 푸리에변환 # 역푸리에변환\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5594be3",
   "metadata": {
    "_cell_guid": "e8220812-116f-4f9b-a855-4b836f7411fc",
    "_uuid": "89ca39590c40bc3e332bab39fcedc7f2670b0f99"
   },
   "source": [
    "## Noise generation functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b765cbe",
   "metadata": {
    "_cell_guid": "890ea515-323c-46ae-884f-9cc71cf19d08",
    "_uuid": "d2d4594b05edbaf2eb450959812b741b8cfed6dc"
   },
   "source": [
    "이 섹션의 코드는 다음 항목에서 차용 및 개조되었습니다.\n",
    "https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a227622",
   "metadata": {
    "_cell_guid": "a401d022-6475-4155-8282-94acd8c81fd7",
    "_uuid": "df4bdf2dc7234238c43e495a393ea824ae5e6e82"
   },
   "outputs": [],
   "source": [
    "def ms(x): # 제곱평균\n",
    "    \"\"\"Mean value of signal `x` squared.\n",
    "    :param x: Dynamic quantity.\n",
    "    :returns: Mean squared of `x`.\n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    \"\"\"normalize power in y to a (standard normal) white noise signal.\n",
    "    Optionally normalize to power in signal `x`.\n",
    "    #The mean power of a Gaussian with :math:`\\\\mu=0` and :math:`\\\\sigma=1` is 1.\n",
    "    \"\"\"\n",
    "    #return y * np.sqrt( (np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean() )\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) ) # y/루트(제곱평균y)\n",
    "    #return y * np.sqrt( 1.0 / (np.abs(y)**2.0).mean() )\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N) # 정규분포\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Blue noise. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with 6 dB per octave.\n",
    "    Power density increases with 3 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise.\n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power decreases with -3 dB per octave.\n",
    "    Power density decreases with 6 dB per octave. \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise. Power increases with 6 dB per octave. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with +9 dB per octave.\n",
    "    Power density increases with +6 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732a917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.59026399, -0.68431962,  1.56870611, -1.10500642, -0.67393401,\n",
       "        0.10376222, -0.31171382, -0.35720405, -0.74424293,  0.12614498])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "state = np.random.RandomState()\n",
    "state.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592bfd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N//2+1+uneven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f775b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17811637,  0.56738609,  0.1139559 , -0.1609064 , -0.0583465 ,\n",
       "        0.09898859])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = state.randn(N//2+1+uneven)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de84143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67854019+0.33696715j, -0.53639523-1.33228336j,\n",
       "       -0.16807449-1.02284005j,  0.57717245+0.56470304j,\n",
       "       -0.563283  +1.19573055j, -1.07630368+0.5818659j ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.random.RandomState()\n",
    "uneven = N%2 # 나머지\n",
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven) #\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd65bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.41421356, 1.73205081, 2.        , 2.23606798,\n",
       "       2.44948974])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309bb7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13220548,  0.52472321,  1.24908875,  0.27902739, -0.36896684,\n",
       "       -0.32109447, -1.36113839, -1.96029794, -0.84810501, -0.38821552])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "y = (irfft(X/S)).real\n",
    "\n",
    "if uneven:\n",
    "    y = y[:-1]\n",
    "normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf1b34",
   "metadata": {
    "_cell_guid": "f08a3dd0-fb34-4415-a24d-795c2a475b3f",
    "_uuid": "a0c5d5315f8f420ba504c26f4ef0ed6d97a4aa57"
   },
   "source": [
    "## Tensorflow utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1d5f5",
   "metadata": {
    "_cell_guid": "f7c51859-aedb-4da5-87e2-8ecf0d41425e",
    "_uuid": "ea75d0aee8fe1d444af7201364c62bc358ba38ab"
   },
   "source": [
    "텐서플로우 공통 작업을 모듈화하기 위한 유틸리티입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde053f",
   "metadata": {
    "_cell_guid": "93fe476d-5f7b-40b1-a074-1a0e9d50ce11",
    "_uuid": "7a782f5e128b8c429c9df8489276c8147ed365f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1): # memory_fraction=1 : 100% 사용 # configuration : 구성\n",
    "    \"\"\"\n",
    "    사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 기능입니다.\n",
    "    1. device: 사용할 장치를 지정합니다(str)\n",
    "    2. memory_fraction: 할당해야 하는 메모리의 비율입니다(float)\n",
    "    3. return: 세션에 전달할 구성입니다(tf 개체)\n",
    "    \"\"\"\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto() \n",
    "    config.allow_soft_placement = True # 선택한 장치가 없으면 다른 장치로 대체\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 장치를 처리하는 텐서플로우 세션을 시작합니다.\n",
    "    이 부분은 미리 인식될 메모리의 비율입니다.\n",
    "    \n",
    "    1. return: configured tf.Session\n",
    "    \"\"\"\n",
    "    return(tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    \"\"\"\n",
    "    For Tensorboard reporting\n",
    "    1. session: opened tensorflow session (tf.Session)\n",
    "    2. logs_path: 텐서보드가 로그를 찾는 경로입니다. (str)\n",
    "    3. project_id: 보고용 프로젝트 이름입니다. (str)\n",
    "    4. version_id: 보고용 버전 이름입니다.(str)\n",
    "    5. return summary_writer: the tensorboard writer\n",
    "    \"\"\"\n",
    "    path = os.path.join(logs_path,\"{}_{}\".format(project_id, version_id)) \n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path) # 전체 디렉터리 트리를 삭제합니다\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n",
    "    \n",
    "    return(summary_writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd97e7",
   "metadata": {
    "_cell_guid": "7dadd066-bd8e-4902-939d-300993467c67",
    "_uuid": "233bef658d360ebf7c9c6f623925615c56ec727b"
   },
   "source": [
    "## Paths management module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66914467",
   "metadata": {
    "_cell_guid": "db84f1ec-e69d-47b6-9bc2-6916a224e905",
    "_uuid": "3bba8797dc146f2a51bc6887aa3d60831745425d"
   },
   "source": [
    "경로를 처리할 모듈입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def abc(x):\n",
    "    def ab(*arg, **kwargs)\n",
    "        return x(*arg, **kwargs)\n",
    "    return ab\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cce78",
   "metadata": {
    "_cell_guid": "98e21f2b-673c-44d3-a156-56278ebe0054",
    "_uuid": "ac2c7e2219c90972ed163a2ce50c2af3c634f8be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common paths\n",
    "def _norm_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력을 정규화하는 데 사용하기 위한 데코레이터 함수입니다.\n",
    "    슬래시/백슬래시 windows 케이스를 수정하는 데 유용합니다.\n",
    "    \"\"\"\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    \n",
    "    return normalize_path\n",
    "\n",
    "\n",
    "def _assure_path_exists(path): # assure : 확신\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력 여부를 확인하기 위한 데코레이터 함수입니다.\n",
    "    fixing the slash/backslash windows cases.\n",
    "    \"\"\"\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p=path(*args, **kwargs)\n",
    "        \n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    \n",
    "    return assure_exists\n",
    "\n",
    "\n",
    "def _is_output_path(path):\n",
    "    \"\"\"\n",
    "    출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "\n",
    "def _is_input_path(path):\n",
    "    \"\"\"\n",
    "    입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"./input/train/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"./input/test/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"../working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"../working/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5eb95",
   "metadata": {
    "_cell_guid": "ee43ab62-3c4a-40dc-9f18-efb0c114505d",
    "_uuid": "fb0647c5bf761a85cfbfc98017dfc428cad260f4"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a492f",
   "metadata": {
    "_cell_guid": "7001ab0b-20f0-44ad-abc9-54c855232c53",
    "_uuid": "46742e27457bae13221a6dd2983aeb05c59b7aaa"
   },
   "source": [
    "일반적인 범용 유틸리티입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3d20c",
   "metadata": {
    "_cell_guid": "c38d1870-b7c4-453e-bf94-1d6226fbe8b8",
    "_uuid": "ca100ad49d05f067cd4c96636a687563581f73d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24649df",
   "metadata": {
    "_cell_guid": "4cf6e246-a187-456d-9b32-4885babd562f",
    "_uuid": "2d0cb1612507e8edcf3752cb3411b4836f6ec800"
   },
   "source": [
    "## Data Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5a459",
   "metadata": {
    "_cell_guid": "0d5b73ee-5261-4ada-8ca1-3bf5a31af487",
    "_uuid": "666ca8a8a9f96b9284d8efa3b5d0f5617661c399"
   },
   "source": [
    "Data handling tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddeb62",
   "metadata": {
    "_cell_guid": "99da70b7-1f49-41f5-bd6b-268429c2d401",
    "_uuid": "87488aa067d32f457072b5816b8f96a45e1add11",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data tools\n",
    "def read_wav(filepath, pad=True):\n",
    "    \"\"\"\n",
    "    wav 파일의 파일 경로를 지정하면 이 함수는 파일을 읽고 정규화하고 패드를 채웁니다.\n",
    "    16k개의 샘플을 가지고 있는지 확인합니다.\n",
    "    1. filepath: wav 파일의 기존 파일 경로입니다. (str)\n",
    "    2. pad: 패딩이 필요합니까? (bool)\n",
    "    3. returns: 표본과 목표 변수 (tuple of (np.array, str))\n",
    "    \"\"\"\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1] # '_background_noise_'\n",
    "    assert sample_rate==16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode=\"constant\")/32768, target\n",
    "    else:\n",
    "        return x/32768, target\n",
    "\n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    \"\"\"\n",
    "    배치 목록이 지정된 배치 생성기를 작성합니다.\n",
    "    1. list_of_paths: 형식 요소가 있는 튜플 리스트입니다. (filepath, target) (list)\n",
    "    2. batch_size: size of the batch (int)\n",
    "    3. label_encoder: fitted LabelEncoder (sklearn.LabelEncoder|optional)\n",
    "    4. scoring: 대상을 고려해야 합니까? (bool)\n",
    "    5. returns: batch generator\n",
    "    \"\"\"\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths))) # map(+1해주는 함수/조건, 반복)\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths # np.row_stack() = np.vstack()\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef954298",
   "metadata": {
    "_cell_guid": "d1472be2-c57a-41be-bf61-c5dea64e9c0c",
    "_uuid": "167d8606f98b87258078ef99d89bf7cc1d84c724"
   },
   "source": [
    "## Architecture building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46621bfa",
   "metadata": {
    "_cell_guid": "a299b242-fd42-4cbf-8181-2bdbd9fa7c3a",
    "_uuid": "fa4997b17d264980689f988e1a50519206d13246"
   },
   "source": [
    "Inception-1D(일명 wavception)는 이 문제를 해결하기 위해 몇 주 전에 설계한 모듈입니다. 그것은 규칙적인 컨볼루션 뉴럴 네트의 성능을 상당히 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ce840",
   "metadata": {
    "_cell_guid": "5f9d3b17-e5b8-4801-a91b-bf9fce956b84",
    "_uuid": "b2e0ccb28bc9a730958a11c6ad35da321ff33db9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name=\"batch_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                            decay=self.momentum,\n",
    "                                            updates_collections=None,\n",
    "                                            epsilon=self.epsilon,\n",
    "                                            scale=True,\n",
    "                                            is_training=train,\n",
    "                                            scope=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):  # depth=1,2,3,4\n",
    "    \"\"\"\n",
    "    (x=self.placeholders.wav_in, is_train=self.placeholders.is_train, \n",
    "                             norm_function=BatchNorm, activ_function=tf.nn.relu, depth=1,\n",
    "                             name=\"Inception_1_1\")\n",
    "                             \n",
    "    Inception 1D 모듈 구현입니다.\n",
    "    1. x: 현재 모듈에 입력합니다. (4D tensor with channels-last)\n",
    "    2. is_train: BatchNormalization 동작을 제어하기 위한 부울 자리 표시자가 되려고 합니다. (0D tensor)\n",
    "    3. depth: 네트워크의 깊이를 선형적으로 제어합니다.(int)\n",
    "    4. norm_function: 정규화 클래스입니다. (same format as the BatchNorm class above)\n",
    "    5. activ_function: 활성화함수 (e.g. tf.nn.relu) \n",
    "    6. name: 변수 범위의 이름입니다. (str)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name=\"norm_input\")(x, train=is_train) # BatchNorm(name='norm_input')(x, train=s)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train) # BatchNorm\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")  # tf.nn.relu\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93514f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WavCeption V1: just a 1-D Inception approach \n",
    "\n",
    "저는 단지 제가 가지고 놀던 작은 장난감을 공유하고 싶었을 뿐인데 **놀라운 결과**를 주었습니다. 지금은 시간이 없기 때문에, 사람들이 어떻게 가지고 놀지 보려고 공유하려고 합니다. :-D. **WavCception V1** 네트워크는 일반 컨볼루션 뉴럴 네트워크에 비해 인상적인 결과를 얻을 수 있는 것으로 보이지만, 이번 경쟁에서는 전처리 및 알려지지 않은 트랙 관리에 많은 노력이 필요한 것으로 보입니다. 이것은 구글의 초기 네트워크를 기반으로 합니다. 같은 아이디어입니다. \n",
    "\n",
    " 저는 몇 주 전에 이러한 모듈들을 캐스케이드로 연결하여 쉽게 1D 인셉션 네트워크를 구축할 수 있도록 구현하는 모듈을 작성했습니다(아래 참조).\n",
    " \n",
    " 아쉽게도 몇 가지 Kaggle의 제약으로 인해 커널 머신에서는 실행되지 않으므로 다운로드하여 자신의 머신에서 실행해 보시기 바랍니다.\n",
    " \n",
    " 너무 고생하지 않고 12시간 동안 모델을 실행함으로써 리더보드에서 0.76을 달성했습니다(로컬 테스트에서는 0.84). 같은 라인의 다른 시험에서는 로컬에서 0.89를 얻었기 때문에 알려지지 않은 클립을 처리하는 방법이 크게 개선되었습니다.\n",
    "\n",
    "## Load modules and libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil # shutil 모듈은 파일과 파일 모음에 대한 여러 가지 고수준 연산을 제공합니다. 특히, 파일 복사와 삭제를 지원하는 함수가 제공됩니다\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm \n",
    "from collections import Counter # Counter('hello world') # Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft # 1차원 이산 푸리에변환 # 역푸리에변환\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "## Noise generation functions \n",
    "\n",
    "이 섹션의 코드는 다음 항목에서 차용 및 개조되었습니다.\n",
    "https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py\n",
    "\n",
    "def ms(x): # 제곱평균\n",
    "    \"\"\"Mean value of signal `x` squared.\n",
    "    :param x: Dynamic quantity.\n",
    "    :returns: Mean squared of `x`.\n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    \"\"\"normalize power in y to a (standard normal) white noise signal.\n",
    "    Optionally normalize to power in signal `x`.\n",
    "    #The mean power of a Gaussian with :math:`\\\\mu=0` and :math:`\\\\sigma=1` is 1.\n",
    "    \"\"\"\n",
    "    #return y * np.sqrt( (np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean() )\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) ) # y/루트(제곱평균y)\n",
    "    #return y * np.sqrt( 1.0 / (np.abs(y)**2.0).mean() )\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N) # 정규분포\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Blue noise. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with 6 dB per octave.\n",
    "    Power density increases with 3 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise.\n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power decreases with -3 dB per octave.\n",
    "    Power density decreases with 6 dB per octave. \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise. Power increases with 6 dB per octave. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with +9 dB per octave.\n",
    "    Power density increases with +6 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "state = np.random.RandomState()\n",
    "state.randn(N)\n",
    "\n",
    "N//2+1+uneven\n",
    "\n",
    "X = state.randn(N//2+1+uneven)\n",
    "X\n",
    "\n",
    "state = np.random.RandomState()\n",
    "uneven = N%2 # 나머지\n",
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven) #\n",
    "X\n",
    "\n",
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "S\n",
    "\n",
    "X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "y = (irfft(X/S)).real\n",
    "\n",
    "if uneven:\n",
    "    y = y[:-1]\n",
    "normalize(y)\n",
    "\n",
    "## Tensorflow utilities\n",
    "\n",
    "텐서플로우 공통 작업을 모듈화하기 위한 유틸리티입니다.\n",
    "\n",
    "\n",
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1): # memory_fraction=1 : 100% 사용 # configuration : 구성\n",
    "    \"\"\"\n",
    "    사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 기능입니다.\n",
    "    1. device: 사용할 장치를 지정합니다(str)\n",
    "    2. memory_fraction: 할당해야 하는 메모리의 비율입니다(float)\n",
    "    3. return: 세션에 전달할 구성입니다(tf 개체)\n",
    "    \"\"\"\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto() \n",
    "    config.allow_soft_placement = True # 선택한 장치가 없으면 다른 장치로 대체\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 장치를 처리하는 텐서플로우 세션을 시작합니다.\n",
    "    이 부분은 미리 인식될 메모리의 비율입니다.\n",
    "    \n",
    "    1. return: configured tf.Session\n",
    "    \"\"\"\n",
    "    return(tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    \"\"\"\n",
    "    For Tensorboard reporting\n",
    "    1. session: opened tensorflow session (tf.Session)\n",
    "    2. logs_path: 텐서보드가 로그를 찾는 경로입니다. (str)\n",
    "    3. project_id: 보고용 프로젝트 이름입니다. (str)\n",
    "    4. version_id: 보고용 버전 이름입니다.(str)\n",
    "    5. return summary_writer: the tensorboard writer\n",
    "    \"\"\"\n",
    "    path = os.path.join(logs_path,\"{}_{}\".format(project_id, version_id)) \n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path) # 전체 디렉터리 트리를 삭제합니다\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n",
    "    \n",
    "    return(summary_writer)\n",
    "\n",
    "\n",
    "## Paths management module\n",
    "\n",
    "경로를 처리할 모듈입니다.\n",
    "\n",
    "\n",
    "'''\n",
    "def abc(x):\n",
    "    def ab(*arg, **kwargs)\n",
    "        return x(*arg, **kwargs)\n",
    "    return ab\n",
    "    \n",
    "'''\n",
    "\n",
    "# Common paths\n",
    "def _norm_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력을 정규화하는 데 사용하기 위한 데코레이터 함수입니다.\n",
    "    슬래시/백슬래시 windows 케이스를 수정하는 데 유용합니다.\n",
    "    \"\"\"\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    \n",
    "    return normalize_path\n",
    "\n",
    "\n",
    "def _assure_path_exists(path): # assure : 확신\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력 여부를 확인하기 위한 데코레이터 함수입니다.\n",
    "    fixing the slash/backslash windows cases.\n",
    "    \"\"\"\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p=path(*args, **kwargs)\n",
    "        \n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    \n",
    "    return assure_exists\n",
    "\n",
    "\n",
    "def _is_output_path(path):\n",
    "    \"\"\"\n",
    "    출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "\n",
    "def _is_input_path(path):\n",
    "    \"\"\"\n",
    "    입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"./input/train/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"./input/test/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"../working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"../working/silence\"\n",
    "    return path\n",
    "\n",
    "## Utilities\n",
    "\n",
    "일반적인 범용 유틸리티입니다.\n",
    "\n",
    "\n",
    "# Utilities\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "## Data Tools\n",
    "\n",
    "Data handling tools\n",
    "\n",
    "# Data tools\n",
    "def read_wav(filepath, pad=True):\n",
    "    \"\"\"\n",
    "    wav 파일의 파일 경로를 지정하면 이 함수는 파일을 읽고 정규화하고 패드를 채웁니다.\n",
    "    16k개의 샘플을 가지고 있는지 확인합니다.\n",
    "    1. filepath: wav 파일의 기존 파일 경로입니다. (str)\n",
    "    2. pad: 패딩이 필요합니까? (bool)\n",
    "    3. returns: 표본과 목표 변수 (tuple of (np.array, str))\n",
    "    \"\"\"\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1] # '_background_noise_'\n",
    "    assert sample_rate==16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode=\"constant\")/32768, target\n",
    "    else:\n",
    "        return x/32768, target\n",
    "\n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    \"\"\"\n",
    "    배치 목록이 지정된 배치 생성기를 작성합니다.\n",
    "    1. list_of_paths: 형식 요소가 있는 튜플 리스트입니다. (filepath, target) (list)\n",
    "    2. batch_size: size of the batch (int)\n",
    "    3. label_encoder: fitted LabelEncoder (sklearn.LabelEncoder|optional)\n",
    "    4. scoring: 대상을 고려해야 합니까? (bool)\n",
    "    5. returns: batch generator\n",
    "    \"\"\"\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths))) # map(+1해주는 함수/조건, 반복)\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths # np.row_stack() = np.vstack()\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)\n",
    "\n",
    "\n",
    "## Architecture building blocks\n",
    "\n",
    "Inception-1D(일명 wavception)는 이 문제를 해결하기 위해 몇 주 전에 설계한 모듈입니다. 그것은 규칙적인 컨볼루션 뉴럴 네트의 성능을 상당히 향상시킵니다.\n",
    "\n",
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name=\"batch_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                            decay=self.momentum,\n",
    "                                            updates_collections=None,\n",
    "                                            epsilon=self.epsilon,\n",
    "                                            scale=True,\n",
    "                                            is_training=train,\n",
    "                                            scope=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):  # depth=1,2,3,4\n",
    "    \"\"\"\n",
    "    (x=self.placeholders.wav_in, is_train=self.placeholders.is_train, \n",
    "                             norm_function=BatchNorm, activ_function=tf.nn.relu, depth=1,\n",
    "                             name=\"Inception_1_1\")\n",
    "                             \n",
    "    Inception 1D 모듈 구현입니다.\n",
    "    1. x: 현재 모듈에 입력합니다. (4D tensor with channels-last)\n",
    "    2. is_train: BatchNormalization 동작을 제어하기 위한 부울 자리 표시자가 되려고 합니다. (0D tensor)\n",
    "    3. depth: 네트워크의 깊이를 선형적으로 제어합니다.(int)\n",
    "    4. norm_function: 정규화 클래스입니다. (same format as the BatchNorm class above)\n",
    "    5. activ_function: 활성화함수 (e.g. tf.nn.relu) \n",
    "    6. name: 변수 범위의 이름입니다. (str)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name=\"norm_input\")(x, train=is_train) # BatchNorm(name='norm_input')(x, train=s)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train) # BatchNorm\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")  # tf.nn.relu\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
